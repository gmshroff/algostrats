{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9a46f5-4d77-4f29-866d-97f2333488a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from tqdm.notebook import tqdm\n",
    "# from matplotlib import pyplot as plt\n",
    "from pandas.tseries.offsets import BDay\n",
    "import pickle\n",
    "import pandas_ta as ta\n",
    "import yfinance as yf\n",
    "import pandas_ta as ta\n",
    "from pandas.tseries.offsets import BDay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f579f8-153a-43e3-a323-3a5d77fb3d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "from india_calendar import IBDay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04074480-bc83-4584-9b6d-7e4ed5a6185e",
   "metadata": {},
   "outputs": [],
   "source": [
    "OHLC_COLS=['Open_n','High_n','Low_n','Close_n']\n",
    "OHLC_ORIG=['Open','High','Low','Close']\n",
    "OHLC_TEMP=['Open_t','High_t','Low_t','Close_t']\n",
    "TA_COLS_OLD=['SMA_10', 'SMA_20', \n",
    "       'VOL_SMA_20','RSI_14','BBL_5_2.0','BBM_5_2.0','BBU_5_2.0',\n",
    "       'BBB_5_2.0', 'BBP_5_2.0','MACD_12_26_9','MACDh_12_26_9','MACDs_12_26_9']\n",
    "TA_COLS=['SMA_10', 'SMA_20','VOL_SMA_20','RSI_14','BBL_5_2.0','BBM_5_2.0','BBU_5_2.0',\n",
    "       'BBB_5_2.0', 'BBP_5_2.0','MACD_12_26_9','MACDh_12_26_9','MACDs_12_26_9','VWAP_D',\n",
    "        'MOM_30', 'CMO_14']\n",
    "TA_COLS_TO_NORM=['SMA_10', 'SMA_20','BBL_5_2.0','BBM_5_2.0','BBU_5_2.0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20faa96-04d4-46b1-84b4-1ca989a677ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_ta(df):\n",
    "    df[TA_COLS]=1.0\n",
    "    df['error']=np.nan\n",
    "    if df.shape[0]>20:\n",
    "        df['error']=0\n",
    "        sma=df.ta.sma()\n",
    "        sma20=df.ta.sma(length=20)\n",
    "        vsma20=df.ta.sma(close=df['Volume'],length=20)\n",
    "        df['SMA_10']=sma\n",
    "        df['SMA_20']=sma20\n",
    "        df['VOL_SMA_20']=vsma20\n",
    "        df.ta.rsi(append=True)\n",
    "        df.ta.bbands(append=True)\n",
    "        df.ta.macd(append=True)\n",
    "        df.ta.vwap(append=True)\n",
    "        df.ta.mom(length=30,append=True)\n",
    "        df.ta.cmo(append=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6f96c6-b46d-4ee0-93b3-944d90de70d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_add_ta(df,drop_ta=False):\n",
    "    dft=df.copy()\n",
    "    if drop_ta: dft=dft.drop(columns=TA_COLS_OLD)\n",
    "    dft[OHLC_TEMP]=dft[OHLC_ORIG]\n",
    "    dft[OHLC_ORIG]=dft[OHLC_COLS]\n",
    "    dft=add_ta(dft)\n",
    "    dft[OHLC_ORIG]=dft[OHLC_TEMP]\n",
    "    dft=dft.drop(columns=OHLC_TEMP)\n",
    "    return dft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e78989e-18d6-4168-b0ac-fa8b3145e521",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_split(df,ticker,date,split):\n",
    "    df1=df.loc[(df['ticker']==ticker)&(pd.to_datetime(df['Date'])<pd.to_datetime(date))]\n",
    "    for c in ['Open','High','Low','Close']: df1[c]=df1[c]/split\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5d000f-2312-415a-9f27-f8f52672461d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hurst(df,lags=[2,20],field='Close'):\n",
    "    input_ts=df[field].values\n",
    "    lagvec=[]\n",
    "    tau=[]\n",
    "    cL=[]\n",
    "    for lag in range(lags[0],lags[1]):\n",
    "        pp=np.subtract(input_ts[lag:],input_ts[:-lag])\n",
    "        lagvec.append(lag)\n",
    "        tau.append(np.std(pp))\n",
    "        #c=np.corrcoef(input_ts[lag:],input_ts[:-lag])\n",
    "        #cL.append(c[0,1])\n",
    "    m=np.polyfit(np.log10(lagvec),np.log10(tau),1)\n",
    "    #alpha=np.polyfit(np.log10(lagvec),np.log10(cL),1)\n",
    "    #plt.plot(np.log10(lagvec),np.log10(cL))\n",
    "    #plt.plot(lagvec,tau)\n",
    "    #H1=1-abs(alpha[0])/2\n",
    "    H=m[0]\n",
    "    return H#,H1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b882c8c1-67b3-4752-9e19-c603c2d79b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_hurst(dft,lags=[2,20],field='Close'):\n",
    "    dates=dft['Date'].unique()\n",
    "    tickers=dft['ticker'].unique()\n",
    "    hL=[]\n",
    "    for t in tqdm(tickers):\n",
    "        for d in tqdm(dates):\n",
    "            H,H1=1,1\n",
    "            df=dft.loc[(dft['Date']==d)&(dft['ticker']==t)]\n",
    "            #print(d,t,df)\n",
    "            if df.shape[0]>=lags[1]: H=hurst(df,lags=lags,field=field)\n",
    "            #print(t,d,H)\n",
    "            ymd=pd.to_datetime(d).strftime('%Y-%m-%d')\n",
    "            hL+=[{'ticker':t,'Prev Date':pd.to_datetime(ymd),'hurst':H}]\n",
    "    hf=pd.DataFrame(hL)\n",
    "    return dft.merge(hf,how='left',on=['ticker','Prev Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b8f5a7-363d-497e-86df-d1bba3e87928",
   "metadata": {},
   "source": [
    "Load prev-days data for month from yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe00c1c-de5c-4466-a1f0-1e1c0fe45136",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aug_prev_day(dft_all,daysfD):\n",
    "    tickers=dft_all['ticker'].unique()\n",
    "    dft_all['Prev Date']=(pd.to_datetime(dft_all['Date'])-BDay(1))\n",
    "    dftL=[]\n",
    "    for t in tqdm(tickers):\n",
    "        dft=dft_all.loc[dft_all['ticker']==t]\n",
    "        daysfD[t]['Prev Date']=daysfD[t].index\n",
    "        dftL+=[pd.merge(dft,daysfD[t],on='Prev Date',suffixes=('','_prev'))]\n",
    "    dft_aug=pd.concat(dftL,axis=0)\n",
    "    return dft_aug"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfb281b-d7af-4261-ac76-e6f48bc886bb",
   "metadata": {},
   "source": [
    "load data for prev month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39696c0-670a-4930-be6f-ddf569264f19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_prev_day_data(dateList,tickers):\n",
    "    std=(pd.to_datetime(dateList[0])-BDay(1)).strftime(\"%Y-%m-%d\")\n",
    "    edt=pd.to_datetime(dateList[-1]).strftime(\"%Y-%m-%d\")\n",
    "    dfD={}\n",
    "    for t in tqdm(tickers):\n",
    "        df=yf.Ticker(t).history(start=std,end=edt,interval='1d')\n",
    "        dfD[t]=df\n",
    "    return dfD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73bbe23-672d-4e6e-ae74-f89f38ab7a73",
   "metadata": {},
   "source": [
    "technical indictoars and normalizatin (earlier was in mlstrats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a69c66c-d339-4d2c-8ba6-dca518a515b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_vol_n(df,sdx): \n",
    "    av=df.loc[(df['row_num']<sdx)&(df['row_num']>=sdx-350)]['Volume'].mean()\n",
    "    df['Volume_n']=df['Volume']/av\n",
    "    return df\n",
    "def feat_aug(df,sdx,tickers,caller=None):\n",
    "    # caller.feat_argsL+=[(df,sdx)]\n",
    "    # r=df['Close'].values[sdx]\n",
    "    r=df.loc[df['row_num']==sdx]['Close'].values[0]\n",
    "    df[OHLC_COLS]=df[OHLC_ORIG]/r\n",
    "    df=add_vol_n(df,sdx)\n",
    "    df=add_addl_features_online(df,tickers)\n",
    "    df=df.fillna(1)\n",
    "    #df[OHLC_COLS+TA_COLS]=df[OHLC_COLS+TA_COLS]-1\n",
    "    df[OHLC_COLS+TA_COLS]=df[OHLC_COLS+TA_COLS]\n",
    "    return df\n",
    "def add_addl_features_online(df,tickers):\n",
    "    def tick_index(t):\n",
    "        if t in tickers: return tickers.index(t)\n",
    "        else: return None\n",
    "    df=norm_add_ta(df,drop_ta=False)\n",
    "    df['sym']=df['ticker'].apply(tick_index)\n",
    "    return df\n",
    "def add_addl_features_feed(feed,tickers,drop_ta=False):\n",
    "    add_ta_features_feed(feed,drop_ta=drop_ta)\n",
    "    # add_sym_feature_feed(feed,tickers)\n",
    "def add_ta_features_feed(feed,drop_ta=False):\n",
    "    dfaL=[]\n",
    "    feed.ndata={}\n",
    "    for t in feed.tickers:\n",
    "        dfa=feed.data[t]\n",
    "        dfL=[]\n",
    "        feed.ndata[t]={}\n",
    "        for d in dfa['Date'].unique():\n",
    "            try:\n",
    "                pdt=pd.to_datetime(d)\n",
    "                pdtp=pdt-IBDay(1)\n",
    "                df=dfa.loc[(pd.to_datetime(dfa['Date'])<=pdt)&\n",
    "                           (pd.to_datetime(dfa['Date'])>=pdtp)]\n",
    "                df['row_num'] = np.arange(len(df))\n",
    "                df=df[~df.index.duplicated(keep='first')]\n",
    "                df=df.sort_index()\n",
    "                sdx=df.loc[df['Date']==d]['row_num'].values[0]\n",
    "                r=df['Close'].values[sdx]\n",
    "                df[OHLC_COLS]=df[OHLC_ORIG]/r\n",
    "                if r==0:\n",
    "                    l=len(df['Close'].values)\n",
    "                    while r==0 and sdx+j<l: \n",
    "                        j+=1\n",
    "                        r=df['Close'].values[sdx+j]\n",
    "                if r!=0: df[OHLC_COLS]=df[OHLC_ORIG]/r\n",
    "                else: df[OHLC_COLS]=1 \n",
    "                df=add_vol_n(df,sdx)\n",
    "                df=norm_add_ta(df,drop_ta=drop_ta)\n",
    "                df['error']=df.isnull().apply(lambda x: -1 if any(x) else 0,axis=1)\n",
    "                df=df.fillna(1)\n",
    "                # df[OHLC_COLS+TA_COLS]=df[OHLC_COLS+TA_COLS]-1\n",
    "                dfc=df.loc[df['Date']==d]\n",
    "                feed.offsets[t][d]=df.shape[0]-dfc.shape[0]\n",
    "                dfL+=[dfc]\n",
    "                # dfL+=[df]\n",
    "                feed.ndata[t][d]=df\n",
    "            except:\n",
    "                pass\n",
    "            #     # feed.ndata[t][d]=pd.DataFrame()\n",
    "        try:\n",
    "            feed.data[t]=pd.concat(dfL,axis=0)\n",
    "            dfaL+=[feed.data[t]]\n",
    "        except:\n",
    "            pass\n",
    "    feed.df=pd.concat(dfaL,axis=0)\n",
    "    feed.df.sort_index(inplace=True)\n",
    "def add_sym_feature_feed(feed,tickers,live=False):\n",
    "    def tick_index(t):\n",
    "        if t in tickers: return tickers.index(t)\n",
    "        else: return None\n",
    "    for t in tickers:\n",
    "        sym=tickers.index(t)\n",
    "        feed.data[t]['sym']=sym\n",
    "        for d in feed.ndata[t]: feed.ndata[t][d]['sym']=sym\n",
    "    if live==False: feed.df['sym']=feed.df['ticker'].apply(tick_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c530490f-8f92-427a-8a94-66271c5f5823",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_global_indices(day=None,global_tickers=None):\n",
    "    dfL=[]\n",
    "    if global_tickers==None: global_tickers=['^NSEI','^NYA','LSEG.L','^IXIC']\n",
    "    for t in global_tickers:\n",
    "        try:\n",
    "            if day==None: df=yf.Ticker(t).history(period='1d',interval='1d')\n",
    "            else: \n",
    "                end=pd.to_datetime(day).strftime('%Y-%m-%d')\n",
    "                start=(pd.to_datetime(day)-IBDay(1)).strftime('%Y-%m-%d')\n",
    "                df=yf.Ticker(t).history(start=start,end=end)\n",
    "            df[['Open_'+t,'High_'+t,'Low_'+t,'Close_'+t]]=df[['Open','High','Low','Close']]/df.Open.values[0]\n",
    "            mv=yf.Ticker(t).history(period='1y',interval='1d')['Volume'].mean()\n",
    "            df['Volume_'+t]=df['Volume']/mv\n",
    "            dfL+=[df[['Open_'+t,'High_'+t,'Low_'+t,'Close_'+t,'Volume_'+t]]]\n",
    "        except:\n",
    "            pass\n",
    "    gf=pd.concat(dfL,axis=1)\n",
    "    return gf.iloc[-1:].to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3e497d-2d82-43eb-a9bb-6855e3ba6021",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_global_indices_feed(feed,global_tickers=None):\n",
    "    feed.gdata={}\n",
    "    for d in feed.dates:\n",
    "        feed.gdata[d]=get_global_indices(day=d,global_tickers=global_tickers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e2d482-d8d5-4785-9b1e-d9462507b8cf",
   "metadata": {},
   "source": [
    "# Experiments/Debugging"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
