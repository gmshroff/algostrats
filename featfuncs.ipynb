{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de9a46f5-4d77-4f29-866d-97f2333488a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from tqdm.notebook import tqdm\n",
    "# from matplotlib import pyplot as plt\n",
    "from pandas.tseries.offsets import BDay\n",
    "import pickle\n",
    "import pandas_ta as ta\n",
    "import yfinance as yf\n",
    "import pandas_ta as ta\n",
    "from pandas.tseries.offsets import BDay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e11a4d-51f5-461b-be2c-085910a1801c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34f579f8-153a-43e3-a323-3a5d77fb3d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from india_calendar.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "from india_calendar import IBDay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04074480-bc83-4584-9b6d-7e4ed5a6185e",
   "metadata": {},
   "outputs": [],
   "source": [
    "OHLC_COLS=['Open_n','High_n','Low_n','Close_n']\n",
    "OHLC_ORIG=['Open','High','Low','Close']\n",
    "OHLC_TEMP=['Open_t','High_t','Low_t','Close_t']\n",
    "TA_COLS_OLD=['SMA_10', 'SMA_20', \n",
    "       'VOL_SMA_20','RSI_14','BBL_5_2.0','BBM_5_2.0','BBU_5_2.0',\n",
    "       'BBB_5_2.0', 'BBP_5_2.0','MACD_12_26_9','MACDh_12_26_9','MACDs_12_26_9']\n",
    "TA_COLS=['SMA_10', 'SMA_20','VOL_SMA_20','RSI_14','BBL_5_2.0','BBM_5_2.0','BBU_5_2.0',\n",
    "       'BBB_5_2.0', 'BBP_5_2.0','MACD_12_26_9','MACDh_12_26_9','MACDs_12_26_9','VWAP_D',\n",
    "        'MOM_30', 'CMO_14']\n",
    "TA_COLS_TO_NORM=['SMA_10', 'SMA_20','BBL_5_2.0','BBM_5_2.0','BBU_5_2.0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1894151-e759-48bb-9ac3-7bf0f4244fe3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "OHLCV_COLS=['Open_n','High_n','Low_n','Close_n','Volume_n']\n",
    "TA_COLS_MIN=['SMA_10', 'SMA_20','CMO_14']\n",
    "LOGICAL_FEATURES=['High_n-Low_n',\n",
    " 'Open_n-Close_n',\n",
    " 'SMA_20-SMA_10',\n",
    " 'Close_n_slope_3',\n",
    " 'Close_n_slope_5',\n",
    " 'Close_n_slope_10',\n",
    " 'Open_n_changelen',\n",
    " 'High_n_changelen',\n",
    " 'Low_n_changelen',\n",
    " 'Close_n_changelen',\n",
    " 'High_n-Low_n_changelen',\n",
    " 'Open_n-Close_n_changelen',\n",
    " 'SMA_20-SMA_10_changelen',\n",
    " 'Close_n_slope_3_changelen',\n",
    " 'Close_n_slope_5_changelen',\n",
    " 'Close_n_slope_10_changelen']\n",
    "GDIM=3\n",
    "MINCOLS=['row_num']+OHLCV_COLS+TA_COLS_MIN\n",
    "ALLCOLS=['row_num']+OHLCV_COLS+TA_COLS\n",
    "MINLOG=['row_num']+OHLCV_COLS+TA_COLS_MIN+LOGICAL_FEATURES\n",
    "ALLLOG=['row_num']+OHLCV_COLS+TA_COLS_MIN+LOGICAL_FEATURES\n",
    "LOGCOLS=['row_num']+OHLCV_COLS+LOGICAL_FEATURES\n",
    "USE_COLS_DICT_ORIG={'allcols':ALLCOLS,'mincols':MINCOLS,'minlog':MINLOG,\n",
    "           'alllog':ALLLOG,'logcols':LOGCOLS}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bee6277e-be33-4c25-9574-d788e580a3a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def update_use_cols_dict(USE_COLS_DICT):\n",
    "    NEWDICT={}\n",
    "    for uc in USE_COLS_DICT:\n",
    "        dc=[]\n",
    "        for c in USE_COLS_DICT[uc]:\n",
    "            if c is not 'row_num': dc+=[c+'_val']\n",
    "            elif c is 'row_num': dc+=[c]\n",
    "        NEWDICT[uc+'D']=dc\n",
    "    for nc in NEWDICT:\n",
    "        USE_COLS_DICT[nc]=NEWDICT[nc]\n",
    "    return USE_COLS_DICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e20faa96-04d4-46b1-84b4-1ca989a677ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_ta(df):\n",
    "    df[TA_COLS]=1.0\n",
    "    df['error']=np.nan\n",
    "    if df.shape[0]>20:\n",
    "        df['error']=0\n",
    "        sma=df.ta.sma()\n",
    "        sma20=df.ta.sma(length=20)\n",
    "        vsma20=df.ta.sma(close=df['Volume'],length=20)\n",
    "        df['SMA_10']=sma\n",
    "        df['SMA_20']=sma20\n",
    "        df['VOL_SMA_20']=vsma20\n",
    "        df.ta.rsi(append=True)\n",
    "        df.ta.bbands(append=True)\n",
    "        df.ta.macd(append=True)\n",
    "        df.ta.vwap(append=True)\n",
    "        df.ta.mom(length=30,append=True)\n",
    "        df.ta.cmo(append=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c6f96c6-b46d-4ee0-93b3-944d90de70d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_add_ta(df,drop_ta=False):\n",
    "    dft=df.copy()\n",
    "    if drop_ta: dft=dft.drop(columns=TA_COLS_OLD)\n",
    "    dft[OHLC_TEMP]=dft[OHLC_ORIG]\n",
    "    dft[OHLC_ORIG]=dft[OHLC_COLS]\n",
    "    dft=add_ta(dft)\n",
    "    dft[OHLC_ORIG]=dft[OHLC_TEMP]\n",
    "    dft=dft.drop(columns=OHLC_TEMP)\n",
    "    return dft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e78989e-18d6-4168-b0ac-fa8b3145e521",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_split(df,ticker,date,split):\n",
    "    df1=df.loc[(df['ticker']==ticker)&(pd.to_datetime(df['Date'])<pd.to_datetime(date))]\n",
    "    for c in ['Open','High','Low','Close']: df1[c]=df1[c]/split\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d5d000f-2312-415a-9f27-f8f52672461d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hurst(df,lags=[2,20],field='Close'):\n",
    "    input_ts=df[field].values\n",
    "    lagvec=[]\n",
    "    tau=[]\n",
    "    cL=[]\n",
    "    for lag in range(lags[0],lags[1]):\n",
    "        pp=np.subtract(input_ts[lag:],input_ts[:-lag])\n",
    "        lagvec.append(lag)\n",
    "        tau.append(np.std(pp))\n",
    "        #c=np.corrcoef(input_ts[lag:],input_ts[:-lag])\n",
    "        #cL.append(c[0,1])\n",
    "    m=np.polyfit(np.log10(lagvec),np.log10(tau),1)\n",
    "    #alpha=np.polyfit(np.log10(lagvec),np.log10(cL),1)\n",
    "    #plt.plot(np.log10(lagvec),np.log10(cL))\n",
    "    #plt.plot(lagvec,tau)\n",
    "    #H1=1-abs(alpha[0])/2\n",
    "    H=m[0]\n",
    "    return H#,H1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b882c8c1-67b3-4752-9e19-c603c2d79b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_hurst(dft,lags=[2,20],field='Close'):\n",
    "    dates=dft['Date'].unique()\n",
    "    tickers=dft['ticker'].unique()\n",
    "    hL=[]\n",
    "    for t in tqdm(tickers):\n",
    "        for d in tqdm(dates):\n",
    "            H,H1=1,1\n",
    "            df=dft.loc[(dft['Date']==d)&(dft['ticker']==t)]\n",
    "            #print(d,t,df)\n",
    "            if df.shape[0]>=lags[1]: H=hurst(df,lags=lags,field=field)\n",
    "            #print(t,d,H)\n",
    "            ymd=pd.to_datetime(d).strftime('%Y-%m-%d')\n",
    "            hL+=[{'ticker':t,'Prev Date':pd.to_datetime(ymd),'hurst':H}]\n",
    "    hf=pd.DataFrame(hL)\n",
    "    return dft.merge(hf,how='left',on=['ticker','Prev Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b8f5a7-363d-497e-86df-d1bba3e87928",
   "metadata": {},
   "source": [
    "Load prev-days data for month from yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0fe00c1c-de5c-4466-a1f0-1e1c0fe45136",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aug_prev_day(dft_all,daysfD):\n",
    "    tickers=dft_all['ticker'].unique()\n",
    "    dft_all['Prev Date']=(pd.to_datetime(dft_all['Date'])-BDay(1))\n",
    "    dftL=[]\n",
    "    for t in tqdm(tickers):\n",
    "        dft=dft_all.loc[dft_all['ticker']==t]\n",
    "        daysfD[t]['Prev Date']=daysfD[t].index\n",
    "        dftL+=[pd.merge(dft,daysfD[t],on='Prev Date',suffixes=('','_prev'))]\n",
    "    dft_aug=pd.concat(dftL,axis=0)\n",
    "    return dft_aug"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfb281b-d7af-4261-ac76-e6f48bc886bb",
   "metadata": {},
   "source": [
    "load data for prev month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d39696c0-670a-4930-be6f-ddf569264f19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_prev_day_data(dateList,tickers):\n",
    "    std=(pd.to_datetime(dateList[0])-BDay(1)).strftime(\"%Y-%m-%d\")\n",
    "    edt=pd.to_datetime(dateList[-1]).strftime(\"%Y-%m-%d\")\n",
    "    dfD={}\n",
    "    for t in tqdm(tickers):\n",
    "        df=yf.Ticker(t).history(start=std,end=edt,interval='1d')\n",
    "        dfD[t]=df\n",
    "    return dfD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73bbe23-672d-4e6e-ae74-f89f38ab7a73",
   "metadata": {},
   "source": [
    "technical indictoars and normalizatin (earlier was in mlstrats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a69c66c-d339-4d2c-8ba6-dca518a515b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_vol_n(df,sdx): \n",
    "    av=df.loc[(df['row_num']<sdx)&(df['row_num']>=sdx-350)]['Volume'].mean()\n",
    "    df['Volume_n']=df['Volume']/av\n",
    "    return df\n",
    "def feat_aug(df,sdx,tickers,caller=None):\n",
    "    # caller.feat_argsL+=[(df,sdx)]\n",
    "    # r=df['Close'].values[sdx]\n",
    "    r=df.loc[df['row_num']==sdx]['Close'].values[0]\n",
    "    df[OHLC_COLS]=df[OHLC_ORIG]/r\n",
    "    df=add_vol_n(df,sdx)\n",
    "    df=add_addl_features_online(df,tickers)\n",
    "    df=df.fillna(1)\n",
    "    #df[OHLC_COLS+TA_COLS]=df[OHLC_COLS+TA_COLS]-1\n",
    "    df[OHLC_COLS+TA_COLS]=df[OHLC_COLS+TA_COLS]\n",
    "    return df\n",
    "def add_addl_features_online(df,tickers):\n",
    "    def tick_index(t):\n",
    "        if t in tickers: return tickers.index(t)\n",
    "        else: return None\n",
    "    df=norm_add_ta(df,drop_ta=False)\n",
    "    df['sym']=df['ticker'].apply(tick_index)\n",
    "    return df\n",
    "def add_addl_features_feed(feed,tickers,drop_ta=False):\n",
    "    add_ta_features_feed(feed,drop_ta=drop_ta)\n",
    "    # add_sym_feature_feed(feed,tickers)\n",
    "def add_ta_features_feed(feed,drop_ta=False):\n",
    "    dfaL=[]\n",
    "    feed.ndata={}\n",
    "    for t in feed.tickers:\n",
    "        dfa=feed.data[t]\n",
    "        dfL=[]\n",
    "        feed.ndata[t]={}\n",
    "        for d in dfa['Date'].unique():\n",
    "            try:\n",
    "                pdt=pd.to_datetime(d)\n",
    "                pdtp=pdt-IBDay(1)\n",
    "                df=dfa.loc[(pd.to_datetime(dfa['Date'])<=pdt)&\n",
    "                           (pd.to_datetime(dfa['Date'])>=pdtp)]\n",
    "                df['row_num'] = np.arange(len(df))\n",
    "                df=df[~df.index.duplicated(keep='first')]\n",
    "                df=df.sort_index()\n",
    "                sdx=df.loc[df['Date']==d]['row_num'].values[0]\n",
    "                r=df['Close'].values[sdx]\n",
    "                df[OHLC_COLS]=df[OHLC_ORIG]/r\n",
    "                if r==0:\n",
    "                    l=len(df['Close'].values)\n",
    "                    while r==0 and sdx+j<l: \n",
    "                        j+=1\n",
    "                        r=df['Close'].values[sdx+j]\n",
    "                if r!=0: df[OHLC_COLS]=df[OHLC_ORIG]/r\n",
    "                else: df[OHLC_COLS]=1 \n",
    "                df=add_vol_n(df,sdx)\n",
    "                df=norm_add_ta(df,drop_ta=drop_ta)\n",
    "                df['error']=df.isnull().apply(lambda x: -1 if any(x) else 0,axis=1)\n",
    "                df=df.fillna(1)\n",
    "                # df[OHLC_COLS+TA_COLS]=df[OHLC_COLS+TA_COLS]-1\n",
    "                dfc=df.loc[df['Date']==d]\n",
    "                feed.offsets[t][d]=df.shape[0]-dfc.shape[0]\n",
    "                dfL+=[dfc]\n",
    "                # dfL+=[df]\n",
    "                feed.ndata[t][d]=df\n",
    "            except:\n",
    "                pass\n",
    "            #     # feed.ndata[t][d]=pd.DataFrame()\n",
    "        try:\n",
    "            feed.data[t]=pd.concat(dfL,axis=0)\n",
    "            dfaL+=[feed.data[t]]\n",
    "        except:\n",
    "            pass\n",
    "    feed.df=pd.concat(dfaL,axis=0)\n",
    "    feed.df.sort_index(inplace=True)\n",
    "def add_sym_feature_feed(feed,tickers,live=False):\n",
    "    def tick_index(t):\n",
    "        if t in tickers: return tickers.index(t)\n",
    "        else: return None\n",
    "    for t in tickers:\n",
    "        sym=tickers.index(t)\n",
    "        feed.data[t]['sym']=sym\n",
    "        for d in feed.ndata[t]: feed.ndata[t][d]['sym']=sym\n",
    "    if live==False: feed.df['sym']=feed.df['ticker'].apply(tick_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c530490f-8f92-427a-8a94-66271c5f5823",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_global_indices(day=None,global_tickers=None):\n",
    "    dfL=[]\n",
    "    if global_tickers==None: global_tickers=['^NSEI','^NYA','LSEG.L','^IXIC']\n",
    "    for t in global_tickers:\n",
    "        try:\n",
    "            if day==None: df=yf.Ticker(t).history(period='1d',interval='1d')\n",
    "            else: \n",
    "                end=pd.to_datetime(day).strftime('%Y-%m-%d')\n",
    "                start=(pd.to_datetime(day)-IBDay(1)).strftime('%Y-%m-%d')\n",
    "                df=yf.Ticker(t).history(start=start,end=end)\n",
    "            df[['Open_'+t,'High_'+t,'Low_'+t,'Close_'+t]]=df[['Open','High','Low','Close']]/df.Open.values[0]\n",
    "            mv=yf.Ticker(t).history(period='1y',interval='1d')['Volume'].mean()\n",
    "            df['Volume_'+t]=df['Volume']/mv\n",
    "            dfL+=[df[['Open_'+t,'High_'+t,'Low_'+t,'Close_'+t,'Volume_'+t]]]\n",
    "        except:\n",
    "            pass\n",
    "    gf=pd.concat(dfL,axis=1)\n",
    "    return gf.iloc[-1:].to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b3e497d-2d82-43eb-a9bb-6855e3ba6021",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_global_indices_feed(feed,global_tickers=None):\n",
    "    feed.gdata={}\n",
    "    for d in feed.dates:\n",
    "        feed.gdata[d]=get_global_indices(day=d,global_tickers=global_tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d40a1d3b-8d55-483e-adcd-df10e66bcb83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_logical_features_feed(feed):\n",
    "\n",
    "    ### LOCAL FUNCTIONS\n",
    "    \n",
    "    def check_numeric(df, col):\n",
    "        return df[col].dtype in ['float64', 'int64']\n",
    "\n",
    "    def difference_cols(df, a, b):\n",
    "        df[f'{a}-{b}'] = df[a] - df[b]\n",
    "        return df, f'{a}-{b}'\n",
    "\n",
    "    def get_ma_base_string(s):\n",
    "        idx = s.find('_ma_')\n",
    "        if idx == -1:\n",
    "            return None\n",
    "        return s[:idx]\n",
    "\n",
    "    def moving_avg(df, col, window_size=3, center=False):\n",
    "        col_name = f'{col}_ma_{window_size}'\n",
    "        df[col_name] = df[col].rolling(window_size, min_periods=1, center=center).mean()\n",
    "        return df, col_name\n",
    "\n",
    "    def slope(df, col, window):\n",
    "        col_name = f'{col}_slope_{window}'\n",
    "        df[col_name] = df[col].diff(periods=window).fillna(df[col])/window\n",
    "        return df, col_name\n",
    "\n",
    "    def max_change_helper(seq):\n",
    "        ans = []\n",
    "        tracker = {i:0 for i in range(seq[-1]+1)}\n",
    "        for i in seq:\n",
    "            tracker[i] += 1\n",
    "            ans.append(tracker[i])\n",
    "        return ans\n",
    "\n",
    "    def max_change(df, col):\n",
    "        inc_tracker = df[col].diff().lt(0).cumsum().values\n",
    "        dec_tracker = df[col].diff().gt(0).cumsum().values\n",
    "\n",
    "        inc_values = max_change_helper(inc_tracker)\n",
    "        dec_values = max_change_helper(dec_tracker)\n",
    "\n",
    "        combined = [inc_values[i]-1 if inc_values[i] >= dec_values[i] \\\n",
    "                    else -dec_values[i]+1 for i in range(len(inc_values))]\n",
    "\n",
    "        col_name = f'{col}_changelen'\n",
    "        df[col_name] = combined\n",
    "        return df, col_name\n",
    "\n",
    "    def discretize(df, col):\n",
    "        stats = df[col].describe()\n",
    "        low_thresh, high_thresh = stats['25%'], stats['75%']\n",
    "        df[f'{col}_val'] = df[col].apply(lambda x: 0 if x<=low_thresh else 2 if x>=high_thresh else 1)\n",
    "        df[f'{col}_polarity'] = df[col].apply(lambda x: 1 if x>0 else -1)\n",
    "        # df[f'{col}_discrete'] = df[f'{col}_val'] + df[f'{col}_polarity']\n",
    "        return df, [f'{col}_val', f'{col}_polarity'] #, f'{col}_discrete']\n",
    "    \n",
    "    ####\n",
    "    \n",
    "    def add_features_df(df):\n",
    "        \n",
    "        nonlocal subtract_cols,slope_cols,change_cols\n",
    "                \n",
    "        columns_to_use = ['Open_n', 'High_n', 'Low_n', 'Close_n']\n",
    "        slope_cols_to_use = ['Close_n']\n",
    "\n",
    "        subtract_col_names = [('High_n', 'Low_n'),('Open_n', 'Close_n'),('SMA_20', 'SMA_10')]\n",
    "        subtract_cols = []\n",
    "\n",
    "        for cols in subtract_col_names:\n",
    "            df, added_col = difference_cols(df, cols[0], cols[1])\n",
    "            subtract_cols.append(added_col)\n",
    "\n",
    "        pre_slope_cols = slope_cols_to_use\n",
    "\n",
    "        window_sizes = [3,5,10]\n",
    "        slope_cols = []\n",
    "\n",
    "        for window in window_sizes:\n",
    "            for col in pre_slope_cols:\n",
    "                df, added_col = slope(df, col, window=window)\n",
    "                slope_cols.append(added_col)\n",
    "\n",
    "        pre_change_cols = columns_to_use + subtract_cols + slope_cols\n",
    "\n",
    "        change_cols = []\n",
    "\n",
    "        for col in pre_change_cols:\n",
    "            df, added_col = max_change(df, col)\n",
    "            change_cols.append(added_col)\n",
    "\n",
    "    # MAIN FUNCTION\n",
    "    subtract_cols,slope_cols,change_cols=[],[],[]\n",
    "    _=[add_features_df(feed.ndata[t][d]) for t in feed.ndata for d in feed.ndata[t]]\n",
    "        \n",
    "    return subtract_cols+slope_cols+change_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a85e8c0d-0581-49ec-8e1a-46e255a40ca8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Discretize dataframe columns with option to keep values within epsilon of 0 as middle bin\n",
    "# use zeromean=True to do above for target column; else use zeromean=False\n",
    "class DiscretizeK:\n",
    "    def __init__(self,epsilon=.001):\n",
    "        self.epsilon=epsilon\n",
    "    def discretizeK(self,df,col,k=5,fit=True,zeromean=True):\n",
    "        epsilon=self.epsilon\n",
    "        def zdisc(x):\n",
    "            estpos,estneg=self.estpos,self.estneg\n",
    "            if x>epsilon: y=estpos.transform(np.array(x).reshape(1,-1))+k2+1\n",
    "            elif x<-epsilon: y=estneg.transform(np.array(x).reshape(1,-1))\n",
    "            else: return k2/4\n",
    "            return y[0][0]/4\n",
    "        if not zeromean:\n",
    "            if fit:\n",
    "                est=KBinsDiscretizer(n_bins=k,encode='ordinal',strategy='quantile')\n",
    "                est.fit(df[col].values.reshape(-1,1))\n",
    "                self.est=est\n",
    "            df[f'{col}_val']=self.est.transform(df[col].values.reshape(-1,1))/4\n",
    "        elif zeromean:\n",
    "            k2=int((k-1)/2)\n",
    "            if fit:\n",
    "                epsilon=self.epsilon\n",
    "                estpos = KBinsDiscretizer(n_bins=k2,encode='ordinal',strategy='quantile')\n",
    "                estpos.fit(df.loc[df[col]>epsilon][col].values.reshape(-1,1))\n",
    "                estneg = KBinsDiscretizer(n_bins=k2,encode='ordinal',strategy='quantile')\n",
    "                estneg.fit(df.loc[df[col]<-epsilon][col].values.reshape(-1,1))\n",
    "                self.estpos,self.estneg=estpos,estneg\n",
    "            df[f'{col}_val']=df[col].apply(zdisc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df300a2e-3bbe-4630-95f7-22e355e5bc03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def discretize_features_feed(feed,DkD,use_cols):\n",
    "    USE_COLS_DICT=update_use_cols_dict(USE_COLS_DICT_ORIG)\n",
    "    cols=USE_COLS_DICT[use_cols]\n",
    "    for t in feed.ndata:\n",
    "        for d in feed.ndata[t]:\n",
    "            df=feed.ndata[t][d]\n",
    "            _=[DkD[c].discretizeK(df,col=c,zeromean=False) for c in cols if c is not 'row_num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622d251f-3999-4334-9a6f-3d2f2645e7fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c9e2d482-d8d5-4785-9b1e-d9462507b8cf",
   "metadata": {},
   "source": [
    "# Experiments/Debugging"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1cd85c87-7e4a-4871-b453-f11d92de3480",
   "metadata": {
    "tags": []
   },
   "source": [
    "from feeds import BackFeed"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4e63986c-24d9-4cdb-81ec-724ea3c90bf1",
   "metadata": {
    "tags": []
   },
   "source": [
    "import pickle\n",
    "with open('../temp_data/btfeed.pickle','rb') as f: feed=pickle.load(f)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "94d693b0-9136-4e14-b3c9-23308cfa349c",
   "metadata": {
    "tags": []
   },
   "source": [
    "feed.dates"
   ]
  },
  {
   "cell_type": "raw",
   "id": "36f62bf6-6f2e-4d06-a621-e7738555f182",
   "metadata": {
    "tags": []
   },
   "source": [
    "L=add_logical_features_feed(feed)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8e6188bd-8a41-43b6-88e8-a726a97248e7",
   "metadata": {
    "tags": []
   },
   "source": [
    "L[1]+L[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c832137-a41f-4f42-bd77-5a2cb64afcce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
