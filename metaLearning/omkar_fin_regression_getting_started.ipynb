{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6607390-c3cf-4624-b7b2-98623ced623e",
   "metadata": {},
   "source": [
    "### Dataset Utilities for Algo-Fin Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0536eb1a-3b33-4c84-be2a-2cd259698dff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "import sklearn.datasets as skds\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "from IPython import display\n",
    "from time import sleep\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import wittgenstein as lw\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85f885c-e271-462c-bc64-99f5e70dff1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "from feeds import DataFeed, BackFeed, USE_COLS_DICT\n",
    "from utils import MyDS\n",
    "import models\n",
    "#from l2lutils import KShotLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85a2d34-28dc-4079-803e-2245edf2db00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier,GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import random_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1324bf-969b-47db-ad01-8834897d8614",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "COLS=['row_num',\n",
    " 'Open_n_val',\n",
    " 'High_n_val',\n",
    " 'Low_n_val',\n",
    " 'Close_n_val',\n",
    " 'Volume_n_val',\n",
    " 'SMA_10_val',\n",
    " 'SMA_20_val',\n",
    " 'CMO_14_val',\n",
    " 'High_n-Low_n_val',\n",
    " 'Open_n-Close_n_val',\n",
    " 'SMA_20-SMA_10_val',\n",
    " 'Close_n_slope_3_val',\n",
    " 'Close_n_slope_5_val',\n",
    " 'Close_n_slope_10_val',\n",
    " 'Open_n_changelen_val',\n",
    " 'High_n_changelen_val',\n",
    " 'Low_n_changelen_val',\n",
    " 'Close_n_changelen_val',\n",
    " 'High_n-Low_n_changelen_val',\n",
    " 'Open_n-Close_n_changelen_val',\n",
    " 'SMA_20-SMA_10_changelen_val',\n",
    " 'Close_n_slope_3_changelen_val',\n",
    " 'Close_n_slope_5_changelen_val',\n",
    " 'Close_n_slope_10_changelen_val']\n",
    "COLS=COLS+['target_5_val','target_10_val','era','day']\n",
    "sigmaL=[[0,0],[0,.05],[.01,0],[.01,.05],[.03,0],[.05,.05],[.075,0],[.075,.05]]\n",
    "DATAPATH='archive/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e5381a-5a57-48c9-9766-3c34b94559d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290a8216-57a2-4e50-ae76-d1caeb25368b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATAPATH='/Users/a112956/DataLocal/fin_regression_summer_proj/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9ae45c-0c3d-46cd-aaa0-fda7b14f56ce",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Load data and set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c9a514-5407-4ca2-9b72-bda281933404",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# To get started choose zero NOISE\n",
    "sid=sigmaL[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01103948-5587-4c42-af12-2f33319e6b1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train=pd.read_csv(DATAPATH+f'df_syn_train_{sid[0]}_{sid[1]}_.csv')[COLS]\n",
    "df_test=pd.read_csv(DATAPATH+f'df_syn_test_{sid[0]}_{sid[1]}_.csv')[COLS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d67c089-bd55-4763-bb1c-57ec17748c1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train_test=pd.read_csv(DATAPATH+f'df_syn_train_test_{sid[0]}_{sid[1]}_.csv')[COLS]\n",
    "df_test_test=pd.read_csv(DATAPATH+f'df_syn_test_test_{sid[0]}_{sid[1]}_.csv')[COLS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412fe0db-386c-4c5c-b770-975207354464",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train.shape,df_test.shape,df_train_test.shape,df_test_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d48f7c7-4ac6-4a24-9b36-5da9b427d05c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eras = df_train['era'].unique()\n",
    "eras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0905991-7e85-4c9d-b109-5422ea7e7cb6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for getting started choose just one era and train/test from same era\n",
    "df=df_train.loc[df_train['era']==9]\n",
    "# df=df_test.loc[df_test['era']==7]\n",
    "trainf=df.iloc[0:int(.8*df.shape[0])]\n",
    "testf=df.iloc[int(.8*df.shape[0]):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d25f9e1-d902-46d6-a2f0-aa5abd22e52d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_train=MyDS(trainf.iloc[:,0:-4].values,trainf.iloc[:,-3].values,task='regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333c9e5c-5015-4dcb-9dc7-d796cdece754",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_test=MyDS(testf.iloc[:,0:-4].values,testf.iloc[:,-3].values,task='regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962f2fcc-3671-40b7-a32c-cb3ca70d3fee",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b562f504-2a4f-44b1-bc52-a52c47c81aae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "rxf = XGBRegressor(max_depth=3, learning_rate=1.0, \\\n",
    "                     n_estimators=500, colsample_bytree=0.1)\n",
    "_ = rxf.fit(ds_train.samples,ds_train.labels)\n",
    "predictions_train=rxf.predict(ds_train.samples.numpy())\n",
    "print(f\"TrainRMSE = {np.sqrt(np.mean((predictions_train-ds_train.labels.numpy())**2))}\")\n",
    "predictions_test=rxf.predict(ds_test.samples.numpy())\n",
    "print(f\"TestRMSE = {np.sqrt(np.mean((predictions_test-ds_test.labels.numpy())**2))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a88cec1-50d3-4ae6-b0f5-0ba890009fdd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier,GradientBoostingRegressor\n",
    "rlf = GradientBoostingRegressor(n_estimators=100, learning_rate=1.0, max_depth=3, random_state=0)\n",
    "_ = rlf.fit(ds_train.samples,ds_train.labels)\n",
    "predictions_train=rlf.predict(ds_train.samples.numpy())\n",
    "print(f\"TrainRMSE = {np.sqrt(np.mean((predictions_train-ds_train.labels.numpy())**2))}\")\n",
    "predictions_test=rlf.predict(ds_test.samples.numpy())\n",
    "print(f\"TestRMSE = {np.sqrt(np.mean((predictions_test-ds_test.labels.numpy())**2))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0763cff-134d-408a-a930-3c98c45c581a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor\n",
    "rfr = RandomForestRegressor()\n",
    "_ = rfr.fit(ds_train.samples,ds_train.labels)\n",
    "predictions_train=rfr.predict(ds_train.samples.numpy())\n",
    "print(f\"TrainRMSE = {np.sqrt(np.mean((predictions_train-ds_train.labels.numpy())**2))}\")\n",
    "predictions_test=rfr.predict(ds_test.samples.numpy())\n",
    "print(f\"TestRMSE = {np.sqrt(np.mean((predictions_test-ds_test.labels.numpy())**2))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e0e3cf-22ba-49a4-8c2b-05114e8bb104",
   "metadata": {},
   "source": [
    "##### Neural network regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0bc1ae-c1d2-4d9f-8664-7590cbf15351",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import import_ipynb\n",
    "import models\n",
    "dsloader = torch.utils.data.DataLoader(dataset=ds_train,batch_size=32, shuffle=True)\n",
    "net = models.MLP(dims=[25, 64, 32, 16], lr = 0.05, task = \"regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa43a36e-f46b-4e36-83f4-471bd43db949",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_train.samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a08ec5-b53f-490b-875e-080f9dc0c24e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "net = models.MLP(dims=[25, 128, 64, 32, 5], lr = 0.001, task = \"classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9549d129-4f9c-4664-a185-85f00053ffca",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "net,losses,accs=models.Train(net,dsloader,epochs=1000, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0318142a-4d37-4535-abf7-b722933027c7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"TrainRMSE = {torch.sqrt(torch.mean((net(torch.tensor(ds_train.samples))-torch.tensor(ds_train.labels))**2))}\")\n",
    "print(f\"TestRMSE = {torch.sqrt(torch.mean((net(torch.tensor(ds_test.samples))-torch.tensor(ds_test.labels))**2))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337a7440-0c39-446b-b9e8-c323220d540c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b50c3d-9068-4807-964e-d2041d7d445b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "present_classes = torch.cat((ds_train.labels, ds_test.labels)).unique()\n",
    "present_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25b8ab2-8bd3-4bfd-9bab-0c37c70d9257",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cxf=XGBClassifier(max_depth=3, learning_rate=0.01, \\\n",
    "                     n_estimators=500, colsample_bytree=0.1)\n",
    "_=cxf.fit(ds_train.samples,[int((present_classes==l).nonzero().item()) for l in ds_train.labels])\n",
    "predictions_train=cxf.predict(ds_train.samples.numpy())\n",
    "print(f\"Train acc = {sum([int(p==l) for p,l in zip(predictions_train,[int((present_classes==l).nonzero().item()) for l in ds_train.labels])])/len(predictions_train)}\")\n",
    "predictions_test=cxf.predict(ds_test.samples.numpy())\n",
    "print(f\"Test acc = {sum([int(p==l) for p,l in zip(predictions_test,[int((present_classes==l).nonzero().item())for l in ds_test.labels])])/len(predictions_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55d1aef-1eed-412a-ae84-7e9ffec500fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1,max_depth=3,random_state=0)\n",
    "_=clf.fit(ds_train.samples,[int((present_classes==l).nonzero().item()) for l in ds_train.labels])\n",
    "predictions_train=clf.predict(ds_train.samples.numpy())\n",
    "print(f\"Train acc = {sum([int(p==l) for p,l in zip(predictions_train,[int((present_classes==l).nonzero().item()) for l in ds_train.labels])])/len(predictions_train)}\")\n",
    "predictions_test=clf.predict(ds_test.samples.numpy())\n",
    "print(f\"Test acc = {sum([int(p==l) for p,l in zip(predictions_test,[int((present_classes==l).nonzero().item())for l in ds_test.labels])])/len(predictions_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d089425-755d-4d84-949d-6801b5e4bf2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=100, learning_rate=1,max_depth=3,random_state=0)\n",
    "_=rfc.fit(ds_train.samples,[int((present_classes==l).nonzero().item()) for l in ds_train.labels])\n",
    "predictions_train=rfc.predict(ds_train.samples.numpy())\n",
    "print(f\"Train acc = {sum([int(p==l) for p,l in zip(predictions_train,[int((present_classes==l).nonzero().item()) for l in ds_train.labels])])/len(predictions_train)}\")\n",
    "predictions_test=rfc.predict(ds_test.samples.numpy())\n",
    "print(f\"Test acc = {sum([int(p==l) for p,l in zip(predictions_test,[int((present_classes==l).nonzero().item())for l in ds_test.labels])])/len(predictions_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8e5a21-86b9-4116-88c5-3f9a962b5b03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "net, train_acc, test_acc = train_mlp(ds_train, ds_test, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d418147-a029-48dd-a376-82adef5260ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5febc0-e799-4b3f-aca1-9ad1d5f1bcc5",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Neural network classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d028b385-cccf-40a0-9f49-772ad3bf9c08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "ds_train.labels=np.array([int((present_classes==l).nonzero().item()) for l in ds_train.labels])\n",
    "ds_test.labels=np.array([int((present_classes==l).nonzero().item()) for l in ds_test.labels])\n",
    "dsloader = torch.utils.data.DataLoader(dataset=ds_train,batch_size=32,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421f3e77-8f0c-48cc-87ee-ef8f91b26b34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_train.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a280a2-f813-4ed1-bde3-13d80bd8118d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "import models\n",
    "net = models.MLP(dims=[25, 64, 32, 5], lr = 0.001)\n",
    "net,losses,accs=models.Train(net,dsloader,epochs=1000,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dd3b0e-5dac-4055-8044-9591069d3a62",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train accuracy\n",
    "print(f\"Train Acc = {models.accuracy(net,torch.tensor(ds_train.samples),torch.tensor(ds_train.labels))}\")\n",
    "# test accuracy\n",
    "print(f\"Train Acc = {models.accuracy(net,torch.tensor(ds_test.samples),torch.tensor(ds_test.labels))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b3fb5c-d746-4fc8-b7cb-95e4c716cc34",
   "metadata": {},
   "source": [
    "##### RIPPER Rule Learner (there is also IREP in the same package) this needs to be debugged first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a134949-4c9d-4987-b345-e12b9be3e4fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_train=MyDS(trainf.iloc[:,0:-4].values,trainf.iloc[:,-3].values,task='regression')\n",
    "ds_test=MyDS(testf.iloc[:,0:-4].values,testf.iloc[:,-3].values,task='regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e719a4-b2aa-4f8d-b694-5ee3b90e5140",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# You will need to install this via pip install wittgenstien\n",
    "import wittgenstein as lw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a32f60-e256-4a7b-8812-209aa0d022a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ripper_clf = lw.RIPPER(max_rules=4,\n",
    "        max_rule_conds=2,\n",
    "        max_total_conds=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b802331d-1170-43ef-b41b-be6e4bdfa4c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# np.array([int(l*4) for l in ds_train.labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23357a0-572e-4376-8ac5-a05bfb358b8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ripper_clf.fit(ds_train.samples.numpy(),np.array([int((present_classes==l).nonzero().item()) for l in ds_train.labels]),pos_class=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cfdbf6-a1f3-4203-857f-3da71fb2fde0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ripper_clf.out_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8dce8b9-113a-4216-9249-aec575d4bd92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# make predictions\n",
    "predictions_train=ripper_clf.predict(ds_train.samples.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8800553-65c0-496b-9877-52a457528b59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# predictions_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537d25b1-b89d-4884-af7c-18a9a1c31783",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def class_accuracy(predictions,y,class_id):\n",
    "    eq=[(lambda x: 1 if x[0]==x[1] else 0)(x) for x in zip(predictions,y==class_id)]\n",
    "    return sum(eq)/len(eq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c63b21b-ad48-447a-b995-ead52277c797",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def class_pos_precision(predictions,y,class_id):\n",
    "    eq=[(lambda x: 1 if (x[0]==x[1] and x[0]==True) else 0)(x) for x in zip(predictions,y==class_id)]\n",
    "    return sum(eq)/len(eq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df866ec-b3bc-4a65-9b8f-710236da7d63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class_accuracy(predictions_train,np.array([int((present_classes==l).nonzero().item()) for l in ds_train.labels]),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ef1c8e-3e2c-48ed-a382-bfcb4efe7cfc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class_pos_precision(predictions_train,np.array([int((present_classes==l).nonzero().item()) for l in ds_train.labels]),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3270f5c4-ec7e-4a1d-95c0-cc9585b69954",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# RIPPER needs debugging - using simpler dataset appears working but not here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7fd639-840f-40c8-b1fc-e518876cbdd3",
   "metadata": {},
   "source": [
    "##### Differentiable rule network - this will need to be extended as part two of the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d72074-42c4-4153-a8ed-42cff6fe4835",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from differentiable_rules import DiffRule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c6b05b-ccaf-45f1-8d12-9eb549a39c01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dr= DiffRule(25,5,3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca2dd9c-1a03-4164-84f1-865611017dda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "net,losses,accs=models.Train(dr,dsloader,epochs=100,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9381a71c-891d-463c-8889-7be69c1ea70e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570a4c59-f753-40ec-b710-ab467afefaac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sample(chunk, rate=0.8):\n",
    "    n = max(int(len(chunk)*rate), 1)\n",
    "    return chunk.sample(n=n, replace=True, random_state=1)\n",
    "    \n",
    "def StratifiedSampler(data, train_size=0.8):\n",
    "    traindf = data.groupby('target_10_val', group_keys=False).apply(sample)\n",
    "    testdf = data.merge(traindf, how=\"left\")\n",
    "    return traindf, testdf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58b68a6-b762-4e2b-9be9-62909ecaebc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_xgbr(ds_train, ds_test, verbose = True):\n",
    "    rxf = XGBRegressor(learning_rate=1.0, \\\n",
    "                         n_estimators=500, colsample_bytree=0.1)\n",
    "    _ = rxf.fit(ds_train.samples,ds_train.labels)\n",
    "    predictions_train=rxf.predict(ds_train.samples.numpy())\n",
    "    predictions_test=rxf.predict(ds_test.samples.numpy())\n",
    "    train_acc = np.sqrt(np.mean((predictions_train-ds_train.labels.numpy())**2))\n",
    "    test_acc = np.sqrt(np.mean((predictions_test-ds_test.labels.numpy())**2))\n",
    "    if verbose:\n",
    "        print(\"XGBR\")\n",
    "        print(f\"TrainRMSE = {train_acc}\")\n",
    "        print(f\"TestRMSE = {test_acc}\")\n",
    "    return rxf, train_acc, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f724e75-84ba-46d6-b0ec-1448cf671246",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_gbr(ds_train, ds_test, verbose = True):\n",
    "    rlf = GradientBoostingRegressor(n_estimators=500, learning_rate=1.0, random_state=0)\n",
    "    _ = rlf.fit(ds_train.samples,ds_train.labels)\n",
    "    predictions_train=rlf.predict(ds_train.samples.numpy())\n",
    "    predictions_test=rlf.predict(ds_test.samples.numpy())\n",
    "    train_acc = np.sqrt(np.mean((predictions_train-ds_train.labels.numpy())**2))\n",
    "    test_acc = np.sqrt(np.mean((predictions_test-ds_test.labels.numpy())**2))\n",
    "    if verbose:\n",
    "        print(\"GBR\")\n",
    "        print(f\"TrainRMSE = {train_acc}\")\n",
    "        print(f\"TestRMSE = {test_acc}\")\n",
    "    return rlf, train_acc, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4c32c8-01fe-413a-887c-b08eae76973b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_rfr(ds_train, ds_test, verbose = True):\n",
    "    rfr = RandomForestRegressor()\n",
    "    _ = rfr.fit(ds_train.samples,ds_train.labels)\n",
    "    predictions_train=rfr.predict(ds_train.samples.numpy())\n",
    "    predictions_test=rfr.predict(ds_test.samples.numpy())\n",
    "    train_acc = np.sqrt(np.mean((predictions_train-ds_train.labels.numpy())**2))\n",
    "    test_acc = np.sqrt(np.mean((predictions_test-ds_test.labels.numpy())**2))\n",
    "    if verbose:\n",
    "        print(\"RFR\")\n",
    "        print(f\"TrainRMSE = {train_acc}\")\n",
    "        print(f\"TestRMSE = {test_acc}\")\n",
    "    return rfr, train_acc, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b648c5b8-a289-47c5-9848-aa5a154c53c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_xgbc(ds_train, ds_test, verbose = True):\n",
    "    present_classes = torch.cat((ds_train.labels, ds_test.labels)).unique()\n",
    "    cxf=XGBClassifier(learning_rate=0.01, \\\n",
    "                         n_estimators=500, colsample_bytree=0.1)\n",
    "    _=cxf.fit(ds_train.samples,[int((present_classes==l).nonzero().item()) for l in ds_train.labels])\n",
    "    predictions_train=cxf.predict(ds_train.samples.numpy())\n",
    "    predictions_test=cxf.predict(ds_test.samples.numpy())\n",
    "    train_acc = sum([int(p==l) for p,l in zip(predictions_train,[int((present_classes==l).nonzero().item()) for l in ds_train.labels])])/len(predictions_train)\n",
    "    test_acc = sum([int(p==l) for p,l in zip(predictions_test,[int((present_classes==l).nonzero().item())for l in ds_test.labels])])/len(predictions_test)\n",
    "    if verbose:\n",
    "        print(\"XGBC\")\n",
    "        print(f\"Train acc = {train_acc}\")\n",
    "        print(f\"Test acc = {test_acc}\")\n",
    "    return cxf, train_acc, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4eeedae-069b-4630-bbaf-10b68d2e4b3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_gbc(ds_train, ds_test, verbose = True):\n",
    "    present_classes = torch.cat((ds_train.labels, ds_test.labels)).unique()\n",
    "    clf = GradientBoostingClassifier(n_estimators=500, max_depth= None,random_state=0)\n",
    "    _=clf.fit(ds_train.samples,[int((present_classes==l).nonzero().item()) for l in ds_train.labels])\n",
    "    predictions_train=clf.predict(ds_train.samples.numpy())\n",
    "    predictions_test=clf.predict(ds_test.samples.numpy())\n",
    "    train_acc = sum([int(p==l) for p,l in zip(predictions_train,[int((present_classes==l).nonzero().item()) for l in ds_train.labels])])/len(predictions_train)\n",
    "    test_acc = sum([int(p==l) for p,l in zip(predictions_test,[int((present_classes==l).nonzero().item())for l in ds_test.labels])])/len(predictions_test)\n",
    "    if verbose:\n",
    "        print(\"GBC\")\n",
    "        print(f\"Train acc = {train_acc}\")\n",
    "        print(f\"Test acc = {test_acc}\")\n",
    "    return clf, train_acc, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2311bf20-b7d3-4713-92a4-f16783841aa4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_rfc(ds_train, ds_test, verbose = True):\n",
    "    present_classes = torch.cat((ds_train.labels, ds_test.labels)).unique()\n",
    "    rfc = RandomForestClassifier(n_estimators=300, max_depth= None,random_state=0)\n",
    "    _=rfc.fit(ds_train.samples,[int((present_classes==l).nonzero().item()) for l in ds_train.labels])\n",
    "    predictions_train=rfc.predict(ds_train.samples.numpy())\n",
    "    predictions_test=rfc.predict(ds_test.samples.numpy())\n",
    "    train_acc = sum([int(p==l) for p,l in zip(predictions_train,[int((present_classes==l).nonzero().item()) for l in ds_train.labels])])/len(predictions_train)\n",
    "    test_acc = sum([int(p==l) for p,l in zip(predictions_test,[int((present_classes==l).nonzero().item())for l in ds_test.labels])])/len(predictions_test)\n",
    "    if verbose:\n",
    "        print(\"RFC\")\n",
    "        print(f\"Train acc = {train_acc}\")\n",
    "        print(f\"Test acc = {test_acc}\")\n",
    "    return rfc, train_acc, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c309d2b5-1062-45e7-8845-e94f78c56502",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_ripper(ds_train, ds_test, verbose = True, max_rules = 15, total_conds =20):\n",
    "    present_classes = torch.cat((ds_train.labels, ds_test.labels)).unique()\n",
    "    ripper_clf = lw.RIPPER(max_rules=max_rules)\n",
    "    _=ripper_clf.fit(ds_train.samples,[int((present_classes==l).nonzero().item()) for l in ds_train.labels])\n",
    "    predictions_train=ripper_clf.predict(ds_train.samples.numpy())\n",
    "    predictions_test=ripper_clf.predict(ds_test.samples.numpy())\n",
    "    train_acc = sum([int(p==l) for p,l in zip(predictions_train,[int((present_classes==l).nonzero().item()) for l in ds_train.labels])])/len(predictions_train)\n",
    "    test_acc = sum([int(p==l) for p,l in zip(predictions_test,[int((present_classes==l).nonzero().item())for l in ds_test.labels])])/len(predictions_test) \n",
    "    if verbose:\n",
    "        print(\"Ripper\")\n",
    "        print(f\"Train acc = {train_acc}\")\n",
    "        print(f\"Test acc = {test_acc}\")\n",
    "    return ripper_clf.out_model(), train_acc, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134224cc-d1fb-4335-af07-29183ccf027c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "import models\n",
    "def train_mlp(ds_train, ds_test, verbose = True, dims=[25, 128, 64, 32, 5], lr = 0.001, epochs = 1000):\n",
    "    present_classes = torch.cat((ds_train.labels, ds_test.labels)).unique()\n",
    "    ds_train.labels=np.array([int((present_classes==l).nonzero().item()) for l in ds_train.labels])\n",
    "    ds_test.labels=np.array([int((present_classes==l).nonzero().item()) for l in ds_test.labels])\n",
    "    dsloader = torch.utils.data.DataLoader(dataset=ds_train,batch_size=32,shuffle=True)\n",
    "    net = models.MLP(dims=dims, lr=lr)\n",
    "    net,losses,accs=models.Train(net,dsloader,epochs=epochs,verbose=True)\n",
    "    train_acc = models.accuracy(net,torch.tensor(ds_train.samples),torch.tensor(ds_train.labels), verbose = False)\n",
    "    test_acc = models.accuracy(net,torch.tensor(ds_test.samples),torch.tensor(ds_test.labels), verbose = False)\n",
    "    if verbose:\n",
    "        print(\"MLPC\")\n",
    "        print(f\"Train acc = {train_acc}\")\n",
    "        print(f\"Test acc = {test_acc}\")\n",
    "    return net, train_acc, test_acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa671069-4a64-4a7b-be4e-826a3d785b64",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## df_syn_train_x_x files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c474d8c-626d-4e62-839c-6a26e2ed80be",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "##training and testing on the same set of eras\n",
    "def train_function(sid, table):\n",
    "    df_train=pd.read_csv(DATAPATH+f'df_syn_train_{sid[0]}_{sid[1]}_.csv')[COLS]\n",
    "    df_test=pd.read_csv(DATAPATH+f'df_syn_test_{sid[0]}_{sid[1]}_.csv')[COLS]\n",
    "    eras = df_train['era'].unique()\n",
    "    trainf = pd.DataFrame()\n",
    "    testf = pd.DataFrame()\n",
    "    for e in eras:\n",
    "        df=df_train.loc[df_train['era'] == e]\n",
    "        train, test = df.iloc[0:int(0.8*df.shape[0])], df.iloc[int(0.8*df.shape[0]):] \n",
    "        trainf = pd.concat([trainf, train])\n",
    "        testf = pd.concat([testf, test])\n",
    "\n",
    "     \n",
    "    ds_train=MyDS(trainf.iloc[:,0:-4].values,trainf.iloc[:,-3].values,task='regression')\n",
    "    ds_test=MyDS(testf.iloc[:,0:-4].values,testf.iloc[:,-3].values,task='regression')\n",
    "\n",
    "    rxf, train_acc, test_acc = train_xgbr(ds_train, ds_test, verbose = False)\n",
    "    table += f\"<td>{train_acc:.3f}</td><td>{test_acc:.3f}</td>\"\n",
    "\n",
    "    rlf, train_acc, test_acc = train_gbr(ds_train, ds_test, verbose = False)\n",
    "    table += f\"<td>{train_acc:.3f}</td><td>{test_acc:.3f}</td>\"\n",
    "\n",
    "    rfr, train_acc, test_acc = train_rfr(ds_train, ds_test, verbose = False)\n",
    "    table += f\"<td>{train_acc:.3f}</td><td>{test_acc:.3f}</td>\"\n",
    "\n",
    "    ds_train=MyDS(trainf.iloc[:,0:-4].values,trainf.iloc[:,-3].values,task='classification')\n",
    "    ds_test=MyDS(testf.iloc[:,0:-4].values,testf.iloc[:,-3].values,task='classification')\n",
    "\n",
    "    #cxf, train_acc, test_acc = train_xgbc(ds_train, ds_test, verbose = False)\n",
    "    #table += f\"<td>{train_acc:.3f}</td><td>{test_acc:.3f}</td>\"\n",
    "    table += f\"<td>0</td><td>0</td>\"\n",
    "\n",
    "    clf, train_acc, test_acc = train_gbc(ds_train, ds_test, verbose = False)\n",
    "    table += f\"<td>{train_acc:.3f}</td><td>{test_acc:.3f}</td>\"\n",
    "\n",
    "    rfc, train_acc, test_acc = train_rfc(ds_train, ds_test, verbose = False)\n",
    "    table += f\"<td>{train_acc:.3f}</td><td>{test_acc:.3f}</td>\"\n",
    "\n",
    "    ripper, train_acc, test_acc = train_ripper(ds_train, ds_test, verbose = False)\n",
    "    table += f\"<td>{train_acc:.3f}</td><td>{test_acc:.3f}</td>\"\n",
    "\n",
    "    net, train_acc, test_acc = train_mlp(ds_train, ds_test, verbose = False)\n",
    "    table += f\"<td>{train_acc:.3f}</td><td>{test_acc:.3f}</td>\"\n",
    "\n",
    "\n",
    "    return table\n",
    "from tqdm import tqdm\n",
    "table = \"<table>\\n\"\n",
    "table += \"<thead><caption>Training on data from all eras with a particular noise (df_syn_train_x_x)</caption>\\n\"\n",
    "table += \"<tr><th colspan=\\\"1\\\">Train Dataset</th><th colspan=\\\"1\\\">Test Dataset</th>\"\n",
    "table += \"<th colspan=\\\"2\\\">XgbR</th><th colspan=\\\"2\\\">GBR</th><th colspan=\\\"2\\\">RFR</th><th colspan=\\\"2\\\">XgbC</th><th colspan=\\\"2\\\">GBC</th><th colspan=\\\"2\\\">RFC</th><th colspan=\\\"2\\\">Ripper</th><th colspan=\\\"2\\\">MLP C</th></tr>\\n\"\n",
    "table += \"</thead>\\n<tbody>\\n\"\n",
    "table += \"<tr><td></td><td></td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td></tr>\"\n",
    "for sid in tqdm(sigmaL):\n",
    "    table += f\"<tr><td>df_syn_train_{sid}</td><td>df_syn_test_{sid}</td>\"\n",
    "    table = train_function(sid, table)\n",
    "    table += \"</tr>\\n\"\n",
    "\n",
    "table += \"</tbody></table>\\n\"\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f01843e-9f30-472e-aad3-7161eb2bd19e",
   "metadata": {},
   "source": [
    "<table>\n",
    "<thead><caption>Training on data from all eras with a particular noise (df_syn_train_x_x)</caption>\n",
    "<tr><th colspan=\"1\">Train Dataset</th><th colspan=\"1\">Test Dataset</th><th colspan=\"2\">XgbR</th><th colspan=\"2\">GBR</th><th colspan=\"2\">RFR</th><th colspan=\"2\">GBC</th><th colspan=\"2\">RFC</th><th colspan=\"2\">Ripper</th><th colspan=\"2\">MLP C</th></tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr><td></td><td></td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td></tr><tr><td>df_syn_train_[0, 0]</td><td>df_syn_test_[0, 0]</td><td>0.053</td><td>0.059</td><td>0.034</td><td>0.059</td><td>0.019</td><td>0.027</td><td>0.999</td><td>0.997</td><td>0.999</td><td>0.998</td><td>0.965</td><td>0.958</td><td>0.997</td><td>0.994</td></tr>\n",
    "<tr><td>df_syn_train_[0, 0.05]</td><td>df_syn_test_[0, 0.05]</td><td>0.080</td><td>0.125</td><td>0.054</td><td>0.116</td><td>0.035</td><td>0.100</td><td>0.996</td><td>0.955</td><td>0.996</td><td>0.961</td><td>0.944</td><td>0.923</td><td>0.989</td><td>0.954</td></tr>\n",
    "<tr><td>df_syn_train_[0.01, 0]</td><td>df_syn_test_[0.01, 0]</td><td>0.182</td><td>0.296</td><td>0.142</td><td>0.285</td><td>0.093</td><td>0.248</td><td>1.000</td><td>0.853</td><td>1.000</td><td>0.899</td><td>0.857</td><td>0.868</td><td>0.991</td><td>0.865</td></tr>\n",
    "<tr><td>df_syn_train_[0.01, 0.05]</td><td>df_syn_test_[0.01, 0.05]</td><td>0.168</td><td>0.268</td><td>0.131</td><td>0.270</td><td>0.083</td><td>0.224</td><td>1.000</td><td>0.872</td><td>1.000</td><td>0.924</td><td>0.883</td><td>0.897</td><td>0.992</td><td>0.874</td></tr>\n",
    "<tr><td>df_syn_train_[0.03, 0]</td><td>df_syn_test_[0.03, 0]</td><td>0.212</td><td>0.342</td><td>0.166</td><td>0.342</td><td>0.110</td><td>0.303</td><td>1.000</td><td>0.787</td><td>1.000</td><td>0.842</td><td>0.828</td><td>0.808</td><td>0.954</td><td>0.785</td></tr>\n",
    "<tr><td>df_syn_train_[0.05, 0.05]</td><td>df_syn_test_[0.05, 0.05]</td><td>0.225</td><td>0.358</td><td>0.174</td><td>0.352</td><td>0.116</td><td>0.312</td><td>1.000</td><td>0.747</td><td>1.000</td><td>0.830</td><td>0.813</td><td>0.799</td><td>0.952</td><td>0.768</td></tr>\n",
    "<tr><td>df_syn_train_[0.075, 0]</td><td>df_syn_test_[0.075, 0]</td><td>0.229</td><td>0.368</td><td>0.178</td><td>0.373</td><td>0.117</td><td>0.330</td><td>1.000</td><td>0.712</td><td>1.000</td><td>0.789</td><td>0.796</td><td>0.793</td><td>0.937</td><td>0.752</td></tr>\n",
    "<tr><td>df_syn_train_[0.075, 0.05]</td><td>df_syn_test_[0.075, 0.05]</td><td>0.228</td><td>0.352</td><td>0.176</td><td>0.359</td><td>0.117</td><td>0.312</td><td>1.000</td><td>0.744</td><td>1.000</td><td>0.828</td><td>0.792</td><td>0.786</td><td>0.938</td><td>0.779</td></tr>\n",
    "</tbody></table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674ad9a5-2b7e-4251-a999-e636bfeb4da9",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "##training on a set of eras but testing on different set\n",
    "def train_function_diff_eras(sid, table):\n",
    "    df_train=pd.read_csv(DATAPATH+f'df_syn_train_{sid[0]}_{sid[1]}_.csv')[COLS]\n",
    "    df_test=pd.read_csv(DATAPATH+f'df_syn_train_test_{sid[0]}_{sid[1]}_.csv')[COLS]\n",
    "    df=df_train\n",
    "    df=df_test\n",
    "    trainf=df_train\n",
    "    testf=df_test\n",
    "\n",
    "    ds_train=MyDS(trainf.iloc[:,0:-4].values,trainf.iloc[:,-3].values,task='regression')\n",
    "    ds_test=MyDS(testf.iloc[:,0:-4].values,testf.iloc[:,-3].values,task='regression')\n",
    "    \n",
    "    rxf, train_acc, test_acc = train_xgbr(ds_train, ds_test, verbose = False)\n",
    "    table += f\"<td>{train_acc:.3f}</td><td>{test_acc:.3f}</td>\"\n",
    "    \n",
    "    rlf, train_acc, test_acc = train_gbr(ds_train, ds_test, verbose = False)\n",
    "    table += f\"<td>{train_acc:.3f}</td><td>{test_acc:.2f}</td>\"\n",
    "    \n",
    "    rfr, train_acc, test_acc = train_rfr(ds_train, ds_test, verbose = False)\n",
    "    table += f\"<td>{train_acc:.3f}</td><td>{test_acc:.3f}</td>\"\n",
    "\n",
    "    ds_train=MyDS(trainf.iloc[:,0:-4].values,trainf.iloc[:,-3].values,task='classification')\n",
    "    ds_test=MyDS(testf.iloc[:,0:-4].values,testf.iloc[:,-3].values,task='classification')\n",
    "    \n",
    "    cxf, train_acc, test_acc = train_xgbc(ds_train, ds_test, verbose = False)\n",
    "    table += f\"<td>{train_acc:.3f}</td><td>{test_acc:.3f}</td>\"\n",
    "    \n",
    "    clf, train_acc, test_acc = train_gbc(ds_train, ds_test, verbose = False)\n",
    "    table += f\"<td>{train_acc:.3f}</td><td>{test_acc:.3f}</td>\"\n",
    "    \n",
    "    rfc, train_acc, test_acc = train_rfc(ds_train, ds_test, verbose = False)\n",
    "    table += f\"<td>{train_acc:.3f}</td><td>{test_acc:.3f}</td>\"\n",
    "\n",
    "    ripper, train_acc, test_acc = train_ripper(ds_train, ds_test, verbose = False)\n",
    "    table += f\"<td>{train_acc:.3f}</td><td>{test_acc:.3f}</td>\"\n",
    "    \n",
    "    net, train_acc, test_acc = train_mlp(ds_train, ds_test, verbose = False)\n",
    "    table += f\"<td>{train_acc:.3f}</td><td>{test_acc:.3f}</td>\"\n",
    "\n",
    "    return table\n",
    "    \n",
    "table = \"<table>\\n\"\n",
    "table += \"<thead><caption>Training on data from a set eras but testing on different eras (train:df_syn_train_x_x, test:df_syn_train_test_x_x)</caption>\\n\"\n",
    "table += \"<tr><th colspan=\\\"1\\\">Train Dataset</th><th colspan=\\\"1\\\">Test Dataset</th>\"\n",
    "table += \"<th colspan=\\\"2\\\">XgbR</th><th colspan=\\\"2\\\">GBR</th><th colspan=\\\"2\\\">RFR</th><th colspan=\\\"2\\\">XgbC</th><th colspan=\\\"2\\\">GBC</th><th colspan=\\\"2\\\">RFC</th><th colspan=\\\"2\\\">Ripper</th><th colspan=\\\"2\\\">MLP C</th></tr>\\n\"\n",
    "table += \"</thead>\\n<tbody>\\n\"\n",
    "table += \"<tr><td></td><td></td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td></tr>\"\n",
    "for sid in tqdm(sigmaL):\n",
    "    table += f\"<tr><td>df_syn_train_{sid}</td><td>df_syn_train_test_{sid}</td>\"\n",
    "    table = train_function_diff_eras(sid, table)\n",
    "    table += \"</tr>\\n\"\n",
    "\n",
    "table += \"</tbody></table>\\n\"\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd79b223-a45b-4266-9a78-7670f756c32e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "##training and testing on the same era\n",
    "def train_function_eras(sid, table):\n",
    "    df_train=pd.read_csv(DATAPATH+f'df_syn_train_{sid[0]}_{sid[1]}_.csv')[COLS]\n",
    "    df_test=pd.read_csv(DATAPATH+f'df_syn_test_{sid[0]}_{sid[1]}_.csv')[COLS]\n",
    "    trainxgbr = []\n",
    "    testxgbr = []\n",
    "    traingbr = []\n",
    "    testgbr = []\n",
    "    trainrfr = []\n",
    "    testrfr = []\n",
    "    trainxgbc = []\n",
    "    testxgbc = []\n",
    "    traingbc = []\n",
    "    testgbc = []\n",
    "    trainrfc = []\n",
    "    testrfc = []\n",
    "    trainmlpc = []\n",
    "    testmlpc = []\n",
    "    trainrip = []\n",
    "    testrip = []\n",
    "    eras = df_train['era'].unique()\n",
    "    \n",
    "    for e in eras:\n",
    "        df=df_train.loc[df_train['era'] == e]\n",
    "        trainf=df.iloc[0:int(.8*df.shape[0])]\n",
    "        testf=df.iloc[int(.8*df.shape[0]):]\n",
    "        ds_train=MyDS(trainf.iloc[:,0:-4].values,trainf.iloc[:,-3].values,task='regression')\n",
    "        ds_test=MyDS(testf.iloc[:,0:-4].values,testf.iloc[:,-3].values,task='regression')\n",
    "        present_classes = torch.cat((ds_train.labels, ds_test.labels)).unique()\n",
    "        if len(present_classes)==1:\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        rxf, train_acc, test_acc = train_xgbr(ds_train, ds_test, verbose = False)\n",
    "        trainxgbr.append(train_acc)\n",
    "        testxgbr.append(test_acc)\n",
    "        \n",
    "        rlf, train_acc, test_acc = train_gbr(ds_train, ds_test, verbose = False)\n",
    "        traingbr.append(train_acc)\n",
    "        testgbr.append(test_acc)\n",
    "        \n",
    "        rfr, train_acc, test_acc = train_rfr(ds_train, ds_test, verbose = False)\n",
    "        trainrfr.append(train_acc)\n",
    "        testrfr.append(test_acc)\n",
    "\n",
    "        ds_train=MyDS(trainf.iloc[:,0:-4].values,trainf.iloc[:,-3].values,task='classification')\n",
    "        ds_test=MyDS(testf.iloc[:,0:-4].values,testf.iloc[:,-3].values,task='classification')\n",
    "        present_classes = torch.cat((ds_train.labels, ds_test.labels)).unique()\n",
    "        if len(present_classes)==1:\n",
    "            continue\n",
    "            \n",
    "        #cxf, train_acc, test_acc = train_xgbc(ds_train, ds_test, verbose = False)\n",
    "        #trainxgbc.append(train_acc)\n",
    "        #testxgbc.append(test_acc)\n",
    "        \n",
    "        clf, train_acc, test_acc = train_gbc(ds_train, ds_test, verbose = False)\n",
    "        traingbc.append(train_acc)\n",
    "        testgbc.append(test_acc)\n",
    "        \n",
    "        rfc, train_acc, test_acc = train_rfc(ds_train, ds_test, verbose = False)\n",
    "        trainrfc.append(train_acc)\n",
    "        testrfc.append(test_acc)\n",
    "\n",
    "        ripper, train_acc, test_acc = train_ripper(ds_train, ds_test, verbose = False)\n",
    "        trainrip.append(train_acc)\n",
    "        testrip.append(test_acc)\n",
    "    \n",
    "        net, train_acc, test_acc = train_mlp(ds_train, ds_test, epochs = 500, verbose = False)\n",
    "        trainmlpc.append(train_acc)\n",
    "        testmlpc.append(test_acc)\n",
    "\n",
    "\n",
    "    table += f\"<td>{sum(trainxgbr)/len(trainxgbr):.2f}</td><td>{sum(testxgbr)/len(testxgbr):.2f}</td>\"\n",
    "    \n",
    "    table += f\"<td>{sum(traingbr)/len(traingbr):.2f}</td><td>{sum(testgbr)/len(testgbr):.2f}</td>\"\n",
    "    \n",
    "    table += f\"<td>{sum(trainrfr)/len(trainrfr):.2f}</td><td>{sum(testrfr)/len(testrfr):.2f}</td>\"\n",
    "    \n",
    "    #table += f\"<td>{sum(trainxgbc)/len(trainxgbc):.2f}</td><td>{sum(testxgbc)/len(testxgbc):.2f}</td>\"\n",
    "    table += f\"<td>0</td><td>0</td>\"\n",
    "    \n",
    "    table += f\"<td>{sum(traingbc)/len(traingbc):.2f}</td><td>{sum(testgbc)/len(testgbc):.2f}</td>\"\n",
    "    \n",
    "    table += f\"<td>{sum(trainrfc)/len(trainrfc):.2f}</td><td>{sum(testrfc)/len(testrfc):.2f}</td>\"\n",
    "\n",
    "    table += f\"<td>{sum(trainrip)/len(trainrip):.2f}</td><td>{sum(testrip)/len(testrip):.2f}</td>\"\n",
    "    \n",
    "    table += f\"<td>{sum(trainmlpc)/len(trainmlpc):.2f}</td><td>{sum(testmlpc)/len(testmlpc):.2f}</td>\"\n",
    "\n",
    "\n",
    "    return table\n",
    "\n",
    "table = \"<table>\\n\"\n",
    "table += \"<thead><caption>Training on data from all eras with a particular noise (df_syn_train_x_x)</caption>\\n\"\n",
    "table += \"<tr><th colspan=\\\"1\\\">Train Dataset</th><th colspan=\\\"1\\\">Test Dataset</th>\"\n",
    "table += \"<th colspan=\\\"2\\\">XgbR</th><th colspan=\\\"2\\\">GBR</th><th colspan=\\\"2\\\">RFR</th><th colspan=\\\"2\\\">XgbC</th><th colspan=\\\"2\\\">GBC</th><th colspan=\\\"2\\\">RFC</th><th colspan=\\\"2\\\">Ripper</th><th colspan=\\\"2\\\">MLP C</th></tr>\\n\"\n",
    "table += \"</thead>\\n<tbody>\\n\"\n",
    "table += \"<tr><td></td><td></td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td></tr>\"\n",
    "for sid in tqdm(sigmaL):\n",
    "    table += f\"<tr><td>df_syn_train_{sid}</td><td>df_syn_test_{sid}</td>\"\n",
    "    table = train_function_eras(sid, table)\n",
    "    table += \"</tr>\\n\"\n",
    "\n",
    "table += \"</tbody></table>\\n\"\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab62a2a-91d5-4f74-8ca7-19e876a9ea95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCombinations(s):\n",
    "    df_train=pd.read_csv(DATAPATH+f'df_syn_train_{s[0]}_{s[1]}_.csv')[COLS]\n",
    "    df_test=pd.read_csv(DATAPATH+f'df_syn_train_test_{s[0]}_{s[1]}_.csv')[COLS]\n",
    "    eras = df_train['era'].unique()\n",
    "    nErasTrain = []\n",
    "    for era in eras:\n",
    "        df=df_train.loc[df_train['era'] == era]\n",
    "        if df['target_10_val'].nunique() == 5:\n",
    "            nErasTrain.append(era)\n",
    "    eras = df_test['era'].unique()\n",
    "    nErasTest = []\n",
    "    for era in eras:\n",
    "        df=df_test.loc[df_test['era'] == era]\n",
    "        if df['target_10_val'].nunique() == 5:\n",
    "            nErasTest.append(era)\n",
    "\n",
    "    if len(nErasTrain) < len(nErasTest):\n",
    "        return zip(nErasTrain * 2, nErasTest)\n",
    "    elif len(nErasTrain) > len(nErasTest):\n",
    "        return zip(nErasTrain, nErasTest * 2)\n",
    "    return zip(nErasTrain, nErasTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e78f067-c647-426e-8f7b-4ee079f0cfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## train on a single era and test on a different era.\n",
    "def train_function_eras_diff_eras(sid, table):\n",
    "    df_train=pd.read_csv(DATAPATH+f'df_syn_train_{sid[0]}_{sid[1]}_.csv')[COLS]\n",
    "    df_test=pd.read_csv(DATAPATH+f'df_syn_train_test_{sid[0]}_{sid[1]}_.csv')[COLS]\n",
    "    df=df_train\n",
    "    df=df_test\n",
    "    for train_era, test_era in getCombinations(sid):\n",
    "        table += f\"<tr><td>df_syn_train_{sid} Era: {train_era}</td><td>df_syn_train_test_{sid} Era: {test_era}</td>\"\n",
    "        trainf=df_train.loc[df_train['era'] == train_era]\n",
    "        testf=df_test.loc[df_test['era'] == test_era]\n",
    "        \n",
    "        ds_train=MyDS(trainf.iloc[:,0:-4].values,trainf.iloc[:,-3].values,task='regression')\n",
    "        ds_test=MyDS(testf.iloc[:,0:-4].values,testf.iloc[:,-3].values,task='regression')\n",
    "\n",
    "        rxf, train_acc, test_acc = train_xgbr(ds_train, ds_test, verbose=False)\n",
    "        table += f\"<td>{train_acc:.3f}</td><td>{test_acc:.3f}</td>\"\n",
    "    \n",
    "        rlf, train_acc, test_acc = train_gbr(ds_train, ds_test, verbose=False)\n",
    "        table += f\"<td>{train_acc:.3f}</td><td>{test_acc:.3f}</td>\"\n",
    "    \n",
    "        rfr, train_acc, test_acc = train_rfr(ds_train, ds_test, verbose=False)\n",
    "        table += f\"<td>{train_acc:.3f}</td><td>{test_acc:.3f}</td>\"\n",
    "\n",
    "        ds_train=MyDS(trainf.iloc[:,0:-4].values,trainf.iloc[:,-3].values,task='classification')\n",
    "        ds_test=MyDS(testf.iloc[:,0:-4].values,testf.iloc[:,-3].values,task='classification')\n",
    "    \n",
    "        #cxf, train_acc, test_acc = train_xgbc(ds_train, ds_test, verbose = False)\n",
    "        #table += f\"<td>{train_acc:.3f}</td><td>{test_acc:.3f}</td>\"\n",
    "        table += f\"<td>0</td><td>0</td>\"\n",
    "    \n",
    "        clf, train_acc, test_acc = train_gbc(ds_train, ds_test, verbose=False)\n",
    "        table += f\"<td>{train_acc:.3f}</td><td>{test_acc:.3f}</td>\"\n",
    "    \n",
    "        rfc, train_acc, test_acc = train_rfc(ds_train, ds_test, verbose=False)\n",
    "        table += f\"<td>{train_acc:.3f}</td><td>{test_acc:.3f}</td>\"\n",
    "\n",
    "        ripper, train_acc, test_acc = train_ripper(ds_train, ds_test, verbose = False)\n",
    "        table += f\"<td>{train_acc:.3f}</td><td>{test_acc:.3f}</td>\"\n",
    "    \n",
    "        net, train_acc, test_acc = train_mlp(ds_train, ds_test, verbose=False)\n",
    "        table += f\"<td>{train_acc:.3f}</td><td>{test_acc:.3f}</td>\"\n",
    "\n",
    "        \n",
    "        table += \"</tr>\"\n",
    "        \n",
    "\n",
    "    return table\n",
    "\n",
    "\n",
    "table = \"<table>\\n\"\n",
    "table += \"<thead><caption>Training on data from a particular era and test on a different era (df_syn_train_x_x, df_syn_test_x_x)</caption>\\n\"\n",
    "table += \"<tr><th colspan=\\\"1\\\">Train Dataset</th><th colspan=\\\"1\\\">Test Dataset</th>\"\n",
    "table += \"<th colspan=\\\"2\\\">XgbR</th><th colspan=\\\"2\\\">GBR</th><th colspan=\\\"2\\\">RFR</th><th colspan=\\\"2\\\">XgbC</th><th colspan=\\\"2\\\">GBC</th><th colspan=\\\"2\\\">RFC</th><th colspan=\\\"2\\\">Ripper</th><th colspan=\\\"2\\\">MLP C</th></tr>\\n\"\n",
    "table += \"</thead>\\n<tbody>\\n\"\n",
    "table += \"<tr><td></td><td></td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td></tr>\"\n",
    "for sid in tqdm(sigmaL):\n",
    "    table = train_function_eras_diff_eras(sid, table)\n",
    "\n",
    "table += \"</tbody></table>\\n\"\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf23e1dc-d223-4899-8780-b0bf15b3043b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training on data with no noise and testing on data with varying levels of noise\n",
    "def train_function(sid, table):\n",
    "    df_train=pd.read_csv(DATAPATH+f'df_syn_train_0_0_.csv')[COLS]\n",
    "    df_test=pd.read_csv(DATAPATH+f'df_syn_train_{sid[0]}_{sid[1]}_.csv')[COLS]\n",
    "    df=df_train\n",
    "    df=df_test\n",
    "    trainf=df_train\n",
    "    testf=df_test\n",
    "\n",
    "    ds_train=MyDS(trainf.iloc[:,0:-4].values,trainf.iloc[:,-3].values,task='regression')\n",
    "    ds_test=MyDS(testf.iloc[:,0:-4].values,testf.iloc[:,-3].values,task='regression')\n",
    "    \n",
    "    rxf, train_acc, test_acc = train_xgbr(ds_train, ds_test, verbose = False)\n",
    "    table += f\"<td>{train_acc:.3f}</td><td>{test_acc:.3f}</td>\"\n",
    "    \n",
    "    rlf, train_acc, test_acc = train_gbr(ds_train, ds_test, verbose = False)\n",
    "    table += f\"<td>{train_acc:.3f}</td><td>{test_acc:.3f}</td>\"\n",
    "    \n",
    "    rfr, train_acc, test_acc = train_rfr(ds_train, ds_test, verbose = False)\n",
    "    table += f\"<td>{train_acc:.3f}</td><td>{test_acc:.3f}</td>\"\n",
    "\n",
    "    ds_train=MyDS(trainf.iloc[:,0:-4].values,trainf.iloc[:,-3].values,task='classification')\n",
    "    ds_test=MyDS(testf.iloc[:,0:-4].values,testf.iloc[:,-3].values,task='classification')\n",
    "    \n",
    "    cxf, train_acc, test_acc = train_xgbc(ds_train, ds_test, verbose = False)\n",
    "    table += f\"<td>{train_acc:.3f}</td><td>{test_acc:.3f}</td>\"\n",
    "    \n",
    "    clf, train_acc, test_acc = train_gbc(ds_train, ds_test, verbose = False)\n",
    "    table += f\"<td>{train_acc:.3f}</td><td>{test_acc:.3f}</td>\"\n",
    "    \n",
    "    rfc, train_acc, test_acc = train_rfc(ds_train, ds_test, verbose = False)\n",
    "    table += f\"<td>{train_acc:.3f}</td><td>{test_acc:.3f}</td>\"\n",
    "\n",
    "    ripper, train_acc, test_acc = train_ripper(ds_train, ds_test, verbose = False)\n",
    "    table += f\"<td>{train_acc:.3f}</td><td>{test_acc:.3f}</td>\"\n",
    "    \n",
    "    net, train_acc, test_acc = train_mlp(ds_train, ds_test, verbose = False)\n",
    "    table += f\"<td>{train_acc:.3f}</td><td>{test_acc:.3f}</td>\"\n",
    "\n",
    "    return table\n",
    "    \n",
    "table = \"<table>\\n\"\n",
    "table += \"<thead><caption>Training on data with no noise and testing on data with varying levels of noise</caption>\\n\"\n",
    "table += \"<tr><th colspan=\\\"1\\\">Train Dataset</th><th colspan=\\\"1\\\">Test Dataset</th>\"\n",
    "table += \"<th colspan=\\\"2\\\">XgbR</th><th colspan=\\\"2\\\">GBR</th><th colspan=\\\"2\\\">RFR</th><th colspan=\\\"2\\\">XgbC</th><th colspan=\\\"2\\\">GBC</th><th colspan=\\\"2\\\">RFC</th><th colspan=\\\"2\\\">Ripper</th><th colspan=\\\"2\\\">MLP C</th></tr>\\n\"\n",
    "table += \"</thead>\\n<tbody>\\n\"\n",
    "table += \"<tr><td></td><td></td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td></tr>\"\n",
    "for sid in tqdm(sigmaL[1:]):\n",
    "    table += f\"<tr><td>df_syn_train_0_0</td><td>df_syn_train_{sid}</td>\"\n",
    "    table = train_function(sid, table)\n",
    "    table += \"</tr>\\n\"\n",
    "\n",
    "table += \"</tbody></table>\\n\"\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee7769e-2efe-4c35-a953-0aacd4b693bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training on data with noise and testing on data with no noise\n",
    "def train_function(sid, table):\n",
    "    df_test=pd.read_csv(DATAPATH+f'df_syn_train_0_0_.csv')[COLS]\n",
    "    df_train=pd.read_csv(DATAPATH+f'df_syn_train_{sid[0]}_{sid[1]}_.csv')[COLS]\n",
    "    df=df_train\n",
    "    df=df_test\n",
    "    trainf=df_train\n",
    "    testf=df_test\n",
    "\n",
    "    ds_train=MyDS(trainf.iloc[:,0:-4].values,trainf.iloc[:,-3].values,task='regression')\n",
    "    ds_test=MyDS(testf.iloc[:,0:-4].values,testf.iloc[:,-3].values,task='regression')\n",
    "    \n",
    "    rxf, train_acc, test_acc = train_xgbr(ds_train, ds_test, verbose = False)\n",
    "    table += f\"<td>{train_acc:.3f}</td><td>{test_acc:.3f}</td>\"\n",
    "    \n",
    "    rlf, train_acc, test_acc = train_gbr(ds_train, ds_test, verbose = False)\n",
    "    table += f\"<td>{train_acc:.3f}</td><td>{test_acc:.3f}</td>\"\n",
    "    \n",
    "    rfr, train_acc, test_acc = train_rfr(ds_train, ds_test, verbose = False)\n",
    "    table += f\"<td>{train_acc:.3f}</td><td>{test_acc:.3f}</td>\"\n",
    "\n",
    "    ds_train=MyDS(trainf.iloc[:,0:-4].values,trainf.iloc[:,-3].values,task='classification')\n",
    "    ds_test=MyDS(testf.iloc[:,0:-4].values,testf.iloc[:,-3].values,task='classification')\n",
    "    \n",
    "    cxf, train_acc, test_acc = train_xgbc(ds_train, ds_test, verbose = False)\n",
    "    table += f\"<td>{train_acc:.3f}</td><td>{test_acc:.3f}</td>\"\n",
    "    \n",
    "    clf, train_acc, test_acc = train_gbc(ds_train, ds_test, verbose = False)\n",
    "    table += f\"<td>{train_acc:.3f}</td><td>{test_acc:.3f}</td>\"\n",
    "    \n",
    "    rfc, train_acc, test_acc = train_rfc(ds_train, ds_test, verbose = False)\n",
    "    table += f\"<td>{train_acc:.3f}</td><td>{test_acc:.3f}</td>\"\n",
    "\n",
    "    ripper, train_acc, test_acc = train_ripper(ds_train, ds_test, verbose = False)\n",
    "    table += f\"<td>{train_acc:.3f}</td><td>{test_acc:.3f}</td>\"\n",
    "    \n",
    "    net, train_acc, test_acc = train_mlp(ds_train, ds_test, verbose = False)\n",
    "    table += f\"<td>{train_acc:.3f}</td><td>{test_acc:.3f}</td>\"\n",
    "\n",
    "\n",
    "    return table\n",
    "    \n",
    "table = \"<table>\\n\"\n",
    "table += \"<thead><caption>Training on data with noise and testing on data with no noise</caption>\\n\"\n",
    "table += \"<tr><th colspan=\\\"1\\\">Train Dataset</th><th colspan=\\\"1\\\">Test Dataset</th>\"\n",
    "table += \"<th colspan=\\\"2\\\">XgbR</th><th colspan=\\\"2\\\">GBR</th><th colspan=\\\"2\\\">RFR</th><th colspan=\\\"2\\\">XgbC</th><th colspan=\\\"2\\\">GBC</th><th colspan=\\\"2\\\">RFC</th><th colspan=\\\"2\\\">Ripper</th><th colspan=\\\"2\\\">MLP C</th></tr>\\n\"\n",
    "table += \"</thead>\\n<tbody>\\n\"\n",
    "table += \"<tr><td></td><td></td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td></tr>\"\n",
    "for sid in tqdm(sigmaL[1:]):\n",
    "    table += f\"<tr><td>df_syn_train_{sid}</td><td>df_syn_train_0_0</td>\"\n",
    "    table = train_function(sid, table)\n",
    "    table += \"</tr>\\n\"\n",
    "\n",
    "table += \"</tbody></table>\\n\"\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521f09e8-9b15-4895-afc7-5e602d44a835",
   "metadata": {},
   "source": [
    "## df_train df_test, df_val files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571c75b9-d410-48ff-9fe1-71e2451a666a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1 = pd.read_csv(DATAPATH+\"df_train.csv\")\n",
    "ds1['era'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a399e3-6a2e-4597-ab28-42ea8936e3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pd.read_csv(DATAPATH+\"df_test.csv\")\n",
    "ds['era'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a413b4a-e0dd-4e7d-8ab9-7905471a55d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e30e5c-7095-4c7a-a37d-899d68dbfc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pd.read_csv(DATAPATH+\"df_val.csv\")\n",
    "ds['era'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f7ab4a-012c-4ce7-9cee-f4803ca88420",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pd.read_csv(DATAPATH+\"df_val_test.csv\")\n",
    "ds['era'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeebe87a-e393-4e55-8b8b-4e9bd6b849dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## training on multiple eras and test on same set of eras\n",
    "def train_function(sid, table, train, test):\n",
    "    df_train=pd.read_csv(train)\n",
    "    df_test=pd.read_csv(test)\n",
    "    eras = df_train['era'].unique()\n",
    "    trainf = pd.DataFrame()\n",
    "    testf = pd.DataFrame()\n",
    "    for e in eras:\n",
    "        df=df_train.loc[df_train['era'] == e]\n",
    "        train, test = df.iloc[0:int(0.8*df.shape[0])], df.iloc[int(0.8*df.shape[0]):] \n",
    "        trainf = pd.concat([trainf, train])\n",
    "        testf = pd.concat([testf, test])\n",
    "    testf = df_test\n",
    "    ds_train=MyDS(trainf.iloc[:,0:-3].values,trainf.iloc[:,-2].values,task='regression')\n",
    "    ds_test=MyDS(testf.iloc[:,0:-3].values,testf.iloc[:,-2].values,task='regression')\n",
    "\n",
    "    rxf, train_acc, test_acc = train_xgbr(ds_train, ds_test, verbose = False)\n",
    "    table += f\"<td>{train_acc:.3f}</td><td>{test_acc:.3f}</td>\"\n",
    "\n",
    "    rlf, train_acc, test_acc = train_gbr(ds_train, ds_test, verbose = False)\n",
    "    table += f\"<td>{train_acc:.3f}</td><td>{test_acc:.3f}</td>\"\n",
    "\n",
    "    rfr, train_acc, test_acc = train_rfr(ds_train, ds_test, verbose = False)\n",
    "    table += f\"<td>{train_acc:.3f}</td><td>{test_acc:.3f}</td>\"\n",
    "\n",
    "    ds_train=MyDS(trainf.iloc[:,0:-3].values,trainf.iloc[:,-2].values,task='classification')\n",
    "    ds_test=MyDS(testf.iloc[:,0:-3].values,testf.iloc[:,-2].values,task='classification')\n",
    "\n",
    "    #cxf, train_acc, test_acc = train_xgbc(ds_train, ds_test, verbose = False)\n",
    "    #table += f\"<td>{train_acc:.3f}</td><td>{test_acc:.3f}</td>\"\n",
    "    table += f\"<td>0</td><td>0</td>\"\n",
    "\n",
    "    clf, train_acc, test_acc = train_gbc(ds_train, ds_test, verbose = False)\n",
    "    table += f\"<td>{train_acc:.3f}</td><td>{test_acc:.3f}</td>\"\n",
    "\n",
    "    rfc, train_acc, test_acc = train_rfc(ds_train, ds_test, verbose = False)\n",
    "    table += f\"<td>{train_acc:.3f}</td><td>{test_acc:.3f}</td>\"\n",
    "\n",
    "    ripper, train_acc, test_acc = train_ripper(ds_train, ds_test, verbose = False)\n",
    "    table += f\"<td>{train_acc:.3f}</td><td>{test_acc:.3f}</td>\"\n",
    "\n",
    "    net, train_acc, test_acc = train_mlp(ds_train, ds_test, verbose = False)\n",
    "    table += f\"<td>{train_acc:.3f}</td><td>{test_acc:.3f}</td>\"\n",
    "\n",
    "    return table\n",
    "from tqdm import tqdm\n",
    "table = \"<table>\\n\"\n",
    "table += \"<thead><caption>Training on data from multiple eras and testing on the same eras</caption>\\n\"\n",
    "table += \"<tr><th colspan=\\\"1\\\">Train Dataset</th><th colspan=\\\"1\\\">Test Dataset</th>\"\n",
    "table += \"<th colspan=\\\"2\\\">XgbR</th><th colspan=\\\"2\\\">GBR</th><th colspan=\\\"2\\\">RFR</th><th colspan=\\\"2\\\">XgbC</th><th colspan=\\\"2\\\">GBC</th><th colspan=\\\"2\\\">RFC</th><th colspan=\\\"2\\\">Ripper</th><th colspan=\\\"2\\\">MLP C</th></tr>\\n\"\n",
    "table += \"</thead>\\n<tbody>\\n\"\n",
    "table += \"<tr><td></td><td></td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td></tr>\"\n",
    "\n",
    "table += f\"<tr><td>df_syn_train</td><td>df_syn_test</td>\"\n",
    "table = train_function(sid, table, DATAPATH+f'df_train.csv', DATAPATH+f'df_test.csv')\n",
    "table += \"</tr>\\n\"\n",
    "\n",
    "table += \"</tbody></table>\\n\"\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb6e622-dc16-4439-92cf-d5958c7f675f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Training on data from set of eras and testing on a different set of eras\n",
    "def train_function(table, train, test):\n",
    "    df_train=pd.read_csv(train)\n",
    "    df_test=pd.read_csv(test)\n",
    "    trainf = df_train.iloc[0:int(df_train.shape[0])]\n",
    "    testf = df_test\n",
    "    ds_train=MyDS(trainf.iloc[:,0:-3].values,trainf.iloc[:,-2].values,task='regression')\n",
    "    ds_test=MyDS(testf.iloc[:,0:-3].values,testf.iloc[:,-2].values,task='regression')\n",
    "    \n",
    "\n",
    "    rxf, train_acc, test_acc = train_xgbr(ds_train, ds_test, verbose = False)\n",
    "    table += f\"<td>{train_acc:.3f}</td><td>{test_acc:.3f}</td>\"\n",
    "\n",
    "    rlf, train_acc, test_acc = train_gbr(ds_train, ds_test, verbose = False)\n",
    "    table += f\"<td>{train_acc:.3f}</td><td>{test_acc:.3f}</td>\"\n",
    "\n",
    "    rfr, train_acc, test_acc = train_rfr(ds_train, ds_test, verbose = False)\n",
    "    table += f\"<td>{train_acc:.3f}</td><td>{test_acc:.3f}</td>\"\n",
    "\n",
    "    ds_train=MyDS(trainf.iloc[:,0:-3].values,trainf.iloc[:,-2].values,task='classification')\n",
    "    ds_test=MyDS(testf.iloc[:,0:-3].values,testf.iloc[:,-2].values,task='classification')\n",
    "    \n",
    "    cxf, train_acc, test_acc = train_xgbc(ds_train, ds_test, verbose = False)\n",
    "    table += f\"<td>{train_acc:.3f}</td><td>{test_acc:.3f}</td>\"\n",
    "\n",
    "    clf, train_acc, test_acc = train_gbc(ds_train, ds_test, verbose = False)\n",
    "    table += f\"<td>{train_acc:.3f}</td><td>{test_acc:.3f}</td>\"\n",
    "\n",
    "    rfc, train_acc, test_acc = train_rfc(ds_train, ds_test, verbose = False)\n",
    "    table += f\"<td>{train_acc:.3f}</td><td>{test_acc:.3f}</td>\"\n",
    "\n",
    "    ripper, train_acc, test_acc = train_ripper(ds_train, ds_test, verbose = False)\n",
    "    table += f\"<td>{train_acc:.3f}</td><td>{test_acc:.3f}</td>\"\n",
    "\n",
    "    net, train_acc, test_acc = train_mlp(ds_train, ds_test, verbose = False)\n",
    "    table += f\"<td>{train_acc:.3f}</td><td>{test_acc:.3f}</td>\"\n",
    "\n",
    "\n",
    "    return table\n",
    "from tqdm import tqdm\n",
    "print(\"table\")\n",
    "table = \"<table>\\n\"\n",
    "table += \"<thead><caption>Training on data from a single era and testing on a different era</caption>\\n\"\n",
    "table += \"<tr><th colspan=\\\"1\\\">Train Dataset</th><th colspan=\\\"1\\\">Test Dataset</th>\"\n",
    "table += \"<th colspan=\\\"2\\\">XgbR</th><th colspan=\\\"2\\\">GBR</th><th colspan=\\\"2\\\">RFR</th><th colspan=\\\"2\\\">XgbC</th><th colspan=\\\"2\\\">GBC</th><th colspan=\\\"2\\\">RFC</th><th colspan=\\\"2\\\">Ripper</th><th colspan=\\\"2\\\">MLP C</th></tr>\\n\"\n",
    "table += \"</thead>\\n<tbody>\\n\"\n",
    "table += \"<tr><td></td><td></td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td></tr>\"\n",
    "\n",
    "table += f\"<tr><td>df_val</td><td>df_val_test</td>\"\n",
    "table = train_function(table, DATAPATH+f'df_val.csv', DATAPATH+f'df_val_test.csv')\n",
    "table += \"</tr>\\n\"\n",
    "table += f\"<tr><td>df_train</td><td>df_val</td>\"\n",
    "table = train_function(table, DATAPATH+f'df_train.csv', DATAPATH+f'df_val.csv')\n",
    "table += \"</tr>\\n\"\n",
    "\n",
    "table += \"</tbody></table>\\n\"\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aed195e-3a23-4d97-9c70-56cc9ba17fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Training on data from a single era and testing it on a different era\n",
    "def train_function(table, train, test):\n",
    "    df_train=pd.read_csv(train)\n",
    "    df_test=pd.read_csv(test)\n",
    "    trainf = df_train\n",
    "    testf = df_test\n",
    "    ds_train=MyDS(trainf.iloc[:,0:-3].values,trainf.iloc[:,-2].values,task='regression')\n",
    "    ds_test=MyDS(testf.iloc[:,0:-3].values,testf.iloc[:,-2].values,task='regression')\n",
    "    train_eras = trainf['era'].unique()\n",
    "    test_eras = testf['era'].unique()\n",
    "    for train_era, test_era in zip(train_eras, test_eras):\n",
    "        \n",
    "        traindf = trainf.loc[trainf['era']==train_era]\n",
    "        testdf = testf.loc[testf['era']==test_era]\n",
    "        \n",
    "        ds_train=MyDS(traindf.iloc[:,0:-3].values,traindf.iloc[:,-2].values,task='regression')\n",
    "        ds_test=MyDS(testdf.iloc[:,0:-3].values,testdf.iloc[:,-2].values,task='regression')\n",
    "\n",
    "        table += f\"<tr><td>{train} {train_era}</td><td>{test} {test_era}</td>\"\n",
    "        \n",
    "        rxf, train_acc, test_acc = train_xgbr(ds_train, ds_test, verbose = False)\n",
    "        table += f\"<td>{train_acc:.3f}</td><td>{test_acc:.3f}</td>\"\n",
    "    \n",
    "        rlf, train_acc, test_acc = train_gbr(ds_train, ds_test, verbose = False)\n",
    "        table += f\"<td>{train_acc:.3f}</td><td>{test_acc:.3f}</td>\"\n",
    "    \n",
    "        rfr, train_acc, test_acc = train_rfr(ds_train, ds_test, verbose = False)\n",
    "        table += f\"<td>{train_acc:.3f}</td><td>{test_acc:.3f}</td>\"\n",
    "\n",
    "        ds_train=MyDS(trainf.iloc[:,0:-3].values,trainf.iloc[:,-2].values,task='classification')\n",
    "        ds_test=MyDS(testf.iloc[:,0:-3].values,testf.iloc[:,-2].values,task='classification')\n",
    "    \n",
    "        cxf, train_acc, test_acc = train_xgbc(ds_train, ds_test, verbose = False)\n",
    "        table += f\"<td>{train_acc:.3f}</td><td>{test_acc:.3f}</td>\"\n",
    "    \n",
    "        clf, train_acc, test_acc = train_gbc(ds_train, ds_test, verbose = False)\n",
    "        table += f\"<td>{train_acc:.3f}</td><td>{test_acc:.3f}</td>\"\n",
    "    \n",
    "        rfc, train_acc, test_acc = train_rfc(ds_train, ds_test, verbose = False)\n",
    "        table += f\"<td>{train_acc:.3f}</td><td>{test_acc:.3f}</td>\"\n",
    "\n",
    "        ripper, train_acc, test_acc = train_ripper(ds_train, ds_test, verbose = False)\n",
    "        table += f\"<td>{train_acc:.3f}</td><td>{test_acc:.3f}</td>\"\n",
    "    \n",
    "        net, train_acc, test_acc = train_mlp(ds_train, ds_test, verbose = False)\n",
    "        table += f\"<td>{train_acc:.3f}</td><td>{test_acc:.3f}</td>\"\n",
    "\n",
    "        table += \"</tr>\\n\"\n",
    "\n",
    "    return table\n",
    "from tqdm import tqdm\n",
    "print(\"table\")\n",
    "table = \"<table>\\n\"\n",
    "table += \"<thead><caption>Training on data from a single era and testing it on a different era</caption>\\n\"\n",
    "table += \"<tr><th colspan=\\\"1\\\">Train Dataset</th><th colspan=\\\"1\\\">Test Dataset</th>\"\n",
    "table += \"<th colspan=\\\"2\\\">XgbR</th><th colspan=\\\"2\\\">GBR</th><th colspan=\\\"2\\\">RFR</th><th colspan=\\\"2\\\">XgbC</th><th colspan=\\\"2\\\">GBC</th><th colspan=\\\"2\\\">RFC</th><th colspan=\\\"2\\\">Ripper</th><th colspan=\\\"2\\\">MLP C</th></tr>\\n\"\n",
    "table += \"</thead>\\n<tbody>\\n\"\n",
    "table += \"<tr><td></td><td></td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td></tr>\"\n",
    "\n",
    "table = train_function(table, DATAPATH+f'df_val.csv', DATAPATH+f'df_val_test.csv')\n",
    "table = train_function(table, DATAPATH+f'df_train.csv', DATAPATH+f'df_val.csv')\n",
    "\n",
    "\n",
    "table += \"</tbody></table>\\n\"\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b493ab-6077-4cd2-8b83-3ea519c78de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Training on data from a single era and testing on the same era\n",
    "def train_function(table, train, test):\n",
    "    df_train=pd.read_csv(train)\n",
    "    df_test=pd.read_csv(test)\n",
    "    trainf = df_train\n",
    "    eras = trainf['era'].unique()\n",
    "    for era in eras:\n",
    "        \n",
    "        ds = trainf.loc[trainf['era']==era]\n",
    "        traindf, testdf = ds.iloc[0:int(0.8*ds.shape[0])], ds.iloc[int(0.8*ds.shape[0]:)]\n",
    "        \n",
    "        ds_train=MyDS(traindf.iloc[:,0:-3].values,traindf.iloc[:,-2].values,task='regression')\n",
    "        ds_test=MyDS(testdf.iloc[:,0:-3].values,testdf.iloc[:,-2].values,task='regression')\n",
    "\n",
    "        table += f\"<tr><td>{train} {era}</td><td>{test} {era}</td>\"\n",
    "        \n",
    "        rxf, train_acc, test_acc = train_xgbr(ds_train, ds_test, verbose = False)\n",
    "        table += f\"<td>{train_acc:.3f}</td><td>{test_acc:.3f}</td>\"\n",
    "    \n",
    "        rlf, train_acc, test_acc = train_gbr(ds_train, ds_test, verbose = False)\n",
    "        table += f\"<td>{train_acc:.3f}</td><td>{test_acc:.3f}</td>\"\n",
    "    \n",
    "        rfr, train_acc, test_acc = train_rfr(ds_train, ds_test, verbose = False)\n",
    "        table += f\"<td>{train_acc:.3f}</td><td>{test_acc:.3f}</td>\"\n",
    "\n",
    "        ds_train=MyDS(trainf.iloc[:,0:-3].values,trainf.iloc[:,-2].values,task='classification')\n",
    "        ds_test=MyDS(testf.iloc[:,0:-3].values,testf.iloc[:,-2].values,task='classification')\n",
    "    \n",
    "        cxf, train_acc, test_acc = train_xgbc(ds_train, ds_test, verbose = False)\n",
    "        table += f\"<td>{train_acc:.3f}</td><td>{test_acc:.3f}</td>\"\n",
    "    \n",
    "        clf, train_acc, test_acc = train_gbc(ds_train, ds_test, verbose = False)\n",
    "        table += f\"<td>{train_acc:.3f}</td><td>{test_acc:.3f}</td>\"\n",
    "    \n",
    "        rfc, train_acc, test_acc = train_rfc(ds_train, ds_test, verbose = False)\n",
    "        table += f\"<td>{train_acc:.3f}</td><td>{test_acc:.3f}</td>\"\n",
    "\n",
    "        ripper, train_acc, test_acc = train_ripper(ds_train, ds_test, verbose = False)\n",
    "        table += f\"<td>{train_acc:.3f}</td><td>{test_acc:.3f}</td>\"\n",
    "    \n",
    "        net, train_acc, test_acc = train_mlp(ds_train, ds_test, verbose = False)\n",
    "        table += f\"<td>{train_acc:.3f}</td><td>{test_acc:.3f}</td>\"\n",
    "\n",
    "        table += \"</tr>\\n\"\n",
    "\n",
    "    return table\n",
    "from tqdm import tqdm\n",
    "print(\"table\")\n",
    "table = \"<table>\\n\"\n",
    "table += \"<thead><caption>Training on data from a single era and testing on the same era</caption>\\n\"\n",
    "table += \"<tr><th colspan=\\\"1\\\">Train Dataset</th><th colspan=\\\"1\\\">Test Dataset</th>\"\n",
    "table += \"<th colspan=\\\"2\\\">XgbR</th><th colspan=\\\"2\\\">GBR</th><th colspan=\\\"2\\\">RFR</th><th colspan=\\\"2\\\">XgbC</th><th colspan=\\\"2\\\">GBC</th><th colspan=\\\"2\\\">RFC</th><th colspan=\\\"2\\\">Ripper</th><th colspan=\\\"2\\\">MLP C</th></tr>\\n\"\n",
    "table += \"</thead>\\n<tbody>\\n\"\n",
    "table += \"<tr><td></td><td></td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td></tr>\"\n",
    "\n",
    "table = train_function(table, DATAPATH+f'df_train.csv', DATAPATH+f'df_test.csv')\n",
    "\n",
    "\n",
    "table += \"</tbody></table>\\n\"\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8c5b37-5a50-47ab-a250-8a2656b95669",
   "metadata": {},
   "source": [
    "# Numerai data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32d54d8-e1a2-42ef-b521-8ce69c21a6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#numerai data IMPORT\n",
    "traindf = pd.read_parquet(\"494_v4_1_train.parquet\")\n",
    "traindf = traindf[traindf.columns[0:-36]]\n",
    "valdf = pd.read_parquet(\"494_v4_1_validation.parquet\")\n",
    "train_eras = traindf['era'].unique()\n",
    "val_eras = valdf['era'].unique()\n",
    "traindf = traindf.loc[traindf['era'].isin(train_eras[-25:])]\n",
    "valdf = valdf.dropna()\n",
    "valdf = valdf[valdf.columns[:-36]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55252c6-1458-4bd0-a511-099dbd55bef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414c63f6-902a-4000-94ab-ed21e89960fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, trainY = traindf[traindf.columns[2:-1]], traindf[traindf.columns[-1]]\n",
    "valX, valY = valdf[valdf.columns[2:-1]], valdf[valdf.columns[-1]]\n",
    "trainY = 4 * trainY\n",
    "valY = 4 * valY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8929075a-1018-48ed-a23b-b70b5ee94583",
   "metadata": {},
   "outputs": [],
   "source": [
    "valX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05168283-7add-409b-b552-4738371878a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_function(table, traindf):\n",
    "    num_samples = len(traindf)\n",
    "    train_eras = traindf['era'].unique()\n",
    "    trainf, testf= pd.DataFrame(), pd.DataFrame()\n",
    "    for e in train_eras:\n",
    "        rows = traindf[traindf['era'] == e].index.to_list()\n",
    "        train_rows = rows[:int(0.8*len(rows))]\n",
    "        test_rows = rows[int(0.8*len(rows)):]\n",
    "        trainf = pd.concat((trainf, traindf.loc[train_rows]))\n",
    "        testf = pd.concat((testf, traindf.loc[test_rows]))\n",
    "        \n",
    "    trainX, trainY = trainf[traindf.columns[2:-1]], trainf[traindf.columns[-1]]\n",
    "    testX, testY = testf[traindf.columns[2:-1]], testf[traindf.columns[-1]]\n",
    "    trainY = 4 * trainY\n",
    "    testY = 4 * testY\n",
    "    \n",
    "    numFeatures = 25\n",
    "    pca = PCA(n_components = numFeatures)\n",
    "    trainX = pca.fit_transform(trainX)\n",
    "    testX = pca.transform(testX)\n",
    "    print(\"pca\")\n",
    "    ds_train=MyDS(trainX,trainY,task='regression')\n",
    "    ds_test=MyDS(testX,testY,task='regression')\n",
    "    \n",
    "    rxf, train_acc, test_acc = train_xgbr(ds_train, ds_test, verbose = False)\n",
    "    table += f\"<td>{train_acc:.2f}</td><td>{test_acc:.2f}</td>\"\n",
    "\n",
    "    rlf, train_acc, test_acc = train_gbr(ds_train, ds_test, verbose = False)\n",
    "    table += f\"<td>{train_acc:.2f}</td><td>{test_acc:.2f}</td>\"\n",
    "\n",
    "    rfr, train_acc, test_acc = train_rfr(ds_train, ds_test, verbose = False)\n",
    "    table += f\"<td>{train_acc:.2f}</td><td>{test_acc:.2f}</td>\"\n",
    "    print(\"reg\")\n",
    "    ds_train=MyDS(trainX,trainY,task='classification')\n",
    "    ds_test=MyDS(testX,testY,task='classification')\n",
    "\n",
    "    cxf, train_acc, test_acc = train_xgbc(ds_train, ds_test, verbose = False)\n",
    "    table += f\"<td>{train_acc:.2f}</td><td>{test_acc:.2f}</td>\"\n",
    "\n",
    "    clf, train_acc, test_acc = train_gbc(ds_train, ds_test, verbose = False)\n",
    "    table += f\"<td>{train_acc:.2f}</td><td>{test_acc:.2f}</td>\"\n",
    "\n",
    "    rfc, train_acc, test_acc = train_rfc(ds_train, ds_test, verbose = False)\n",
    "    table += f\"<td>{train_acc:.2f}</td><td>{test_acc:.2f}</td>\"\n",
    "\n",
    "    ripper, train_acc, test_acc = train_ripper(ds_train, ds_test, verbose = False)\n",
    "    table += f\"<td>{train_acc:.2f}</td><td>{test_acc:.2f}</td>\"\n",
    "\n",
    "    net, train_acc, test_acc = train_mlp(ds_train, ds_test, verbose = False)\n",
    "    table += f\"<td>{train_acc:.2f}</td><td>{test_acc:.2f}</td>\"\n",
    "\n",
    "    table += \"</tr>\\n\"\n",
    "\n",
    "    return table    \n",
    "\n",
    "from tqdm import tqdm\n",
    "print(\"table\")\n",
    "table = \"<table>\\n\"\n",
    "table += \"<thead><caption>Training on data from all eras and testing on data with all different eras.</caption>\\n\"\n",
    "table += \"<tr><th colspan=\\\"1\\\">Train Dataset</th><th colspan=\\\"1\\\">Test Dataset</th>\"\n",
    "table += \"<th colspan=\\\"2\\\">XgbR</th><th colspan=\\\"2\\\">GBR</th><th colspan=\\\"2\\\">RFR</th><th colspan=\\\"2\\\">XgbC</th><th colspan=\\\"2\\\">GBC</th><th colspan=\\\"2\\\">RFC</th><th colspan=\\\"2\\\">Ripper</th><th colspan=\\\"2\\\">MLP C</th></tr>\\n\"\n",
    "table += \"</thead>\\n<tbody>\\n\"\n",
    "table += \"<tr><td></td><td></td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td></tr>\"\n",
    "table += f\"<tr><td colspan =\\\"2\\\">train</td>\"\n",
    "table = train_function(table, traindf)\n",
    "table += \"</tbody></table>\\n\"\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b4f930-62f3-490f-926f-2035dd2dac04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_function(table, trainX, trainY, testX, testY):\n",
    "    ds_train=MyDS(trainX,trainY,task='regression')\n",
    "    ds_test=MyDS(testX,testY,task='regression')\n",
    "    \n",
    "    rxf, train_acc, test_acc = train_xgbr(ds_train, ds_test, verbose = False)\n",
    "    table += f\"<td>{train_acc:.2f}</td><td>{test_acc:.2f}</td>\"\n",
    "\n",
    "    rlf, train_acc, test_acc = train_gbr(ds_train, ds_test, verbose = False)\n",
    "    table += f\"<td>{train_acc:.2f}</td><td>{test_acc:.2f}</td>\"\n",
    "\n",
    "    rfr, train_acc, test_acc = train_rfr(ds_train, ds_test, verbose = False)\n",
    "    table += f\"<td>{train_acc:.2f}</td><td>{test_acc:.2f}</td>\"\n",
    "\n",
    "    ds_train=MyDS(trainX,trainY,task='classification')\n",
    "    ds_test=MyDS(testX,testY,task='classification')\n",
    "\n",
    "    cxf, train_acc, test_acc = train_xgbc(ds_train, ds_test, verbose = False)\n",
    "    table += f\"<td>{train_acc:.2f}</td><td>{test_acc:.2f}</td>\"\n",
    "\n",
    "    clf, train_acc, test_acc = train_gbc(ds_train, ds_test, verbose = False)\n",
    "    table += f\"<td>{train_acc:.2f}</td><td>{test_acc:.2f}</td>\"\n",
    "\n",
    "    rfc, train_acc, test_acc = train_rfc(ds_train, ds_test, verbose = False)\n",
    "    table += f\"<td>{train_acc:.2f}</td><td>{test_acc:.2f}</td>\"\n",
    "\n",
    "    net, train_acc, test_acc = train_mlp(ds_train, ds_test, verbose = False)\n",
    "    table += f\"<td>{train_acc:.2f}</td><td>{test_acc:.2f}</td>\"\n",
    "\n",
    "    table += \"</tr>\\n\"\n",
    "\n",
    "    return table\n",
    "from tqdm import tqdm\n",
    "print(\"table\")\n",
    "table = \"<table>\\n\"\n",
    "table += \"<thead><caption>Training on data from all eras and testing on data with all different eras.</caption>\\n\"\n",
    "table += \"<tr><th colspan=\\\"1\\\">Train Dataset</th><th colspan=\\\"1\\\">Test Dataset</th>\"\n",
    "table += \"<th colspan=\\\"2\\\">XgbR</th><th colspan=\\\"2\\\">GBR</th><th colspan=\\\"2\\\">RFR</th><th colspan=\\\"2\\\">XgbC</th><th colspan=\\\"2\\\">GBC</th><th colspan=\\\"2\\\">RFC</th><th colspan=\\\"2\\\">MLP C</th></tr>\\n\"\n",
    "table += \"</thead>\\n<tbody>\\n\"\n",
    "table += \"<tr><td></td><td></td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td></tr>\"\n",
    "table += f\"<tr><td>train</td><td>validation</td>\"\n",
    "\n",
    "table = train_function(table, trainX, trainY, valX, valY)\n",
    "\n",
    "\n",
    "table += \"</tbody></table>\\n\"\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1621f7ed-069b-4cf2-8c34-8764a3103542",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_function(table, traindf):\n",
    "    num_samples = len(traindf)\n",
    "    eras = traindf['era'].unique()\n",
    "    for era in eras:\n",
    "        df= traindf[traindf['era'] == era]\n",
    "        trainf = df.iloc[:int(0.8*len(df))]\n",
    "        testf = df.iloc[int(0.8*len(df)):]\n",
    "        \n",
    "        trainX, trainY = trainf[traindf.columns[2:-1]].values, trainf[traindf.columns[-1]].values\n",
    "        testX, testY = testf[traindf.columns[2:-1]].values, testf[traindf.columns[-1]].values\n",
    "        trainY = 4 * trainY\n",
    "        testY = 4 * testY\n",
    "        \n",
    "        numFeatures = 25\n",
    "        pca = PCA(n_components = numFeatures)\n",
    "        trainX = pca.fit_transform(trainX)\n",
    "        testX = pca.transform(testX)\n",
    "        print(\"pca\")\n",
    "        ds_train=MyDS(trainX,trainY,task='regression')\n",
    "        ds_test=MyDS(testX,testY,task='regression')\n",
    "        table += f\"<tr><td colspan = \\\"2\\\">{era}</td>\"\n",
    "        rxf, train_acc, test_acc = train_xgbr(ds_train, ds_test, verbose = False)\n",
    "        table += f\"<td>{train_acc:.2f}</td><td>{test_acc:.2f}</td>\"\n",
    "    \n",
    "        rlf, train_acc, test_acc = train_gbr(ds_train, ds_test, verbose = False)\n",
    "        table += f\"<td>{train_acc:.2f}</td><td>{test_acc:.2f}</td>\"\n",
    "    \n",
    "        rfr, train_acc, test_acc = train_rfr(ds_train, ds_test, verbose = False)\n",
    "        table += f\"<td>{train_acc:.2f}</td><td>{test_acc:.2f}</td>\"\n",
    "        print(\"reg\")\n",
    "        ds_train=MyDS(trainX,trainY,task='classification')\n",
    "        ds_test=MyDS(testX,testY,task='classification')\n",
    "    \n",
    "        cxf, train_acc, test_acc = train_xgbc(ds_train, ds_test, verbose = False)\n",
    "        table += f\"<td>{train_acc:.2f}</td><td>{test_acc:.2f}</td>\"\n",
    "    \n",
    "        clf, train_acc, test_acc = train_gbc(ds_train, ds_test, verbose = False)\n",
    "        table += f\"<td>{train_acc:.2f}</td><td>{test_acc:.2f}</td>\"\n",
    "    \n",
    "        rfc, train_acc, test_acc = train_rfc(ds_train, ds_test, verbose = False)\n",
    "        table += f\"<td>{train_acc:.2f}</td><td>{test_acc:.2f}</td>\"\n",
    "    \n",
    "        net, train_acc, test_acc = train_mlp(ds_train, ds_test, verbose = False)\n",
    "        table += f\"<td>{train_acc:.2f}</td><td>{test_acc:.2f}</td>\"\n",
    "    \n",
    "        table += \"</tr>\\n\"\n",
    "\n",
    "    return table    \n",
    "from tqdm import tqdm\n",
    "print(\"table\")\n",
    "table = \"<table>\\n\"\n",
    "table += \"<thead><caption>Training on data from a single era and test on same era.</caption>\\n\"\n",
    "table += \"<tr><th colspan=\\\"1\\\">Train Dataset</th><th colspan=\\\"1\\\">Test Dataset</th>\"\n",
    "table += \"<th colspan=\\\"2\\\">XgbR</th><th colspan=\\\"2\\\">GBR</th><th colspan=\\\"2\\\">RFR</th><th colspan=\\\"2\\\">XgbC</th><th colspan=\\\"2\\\">GBC</th><th colspan=\\\"2\\\">RFC</th><th colspan=\\\"2\\\">MLP C</th></tr>\\n\"\n",
    "table += \"</thead>\\n<tbody>\\n\"\n",
    "table += \"<tr><td></td><td></td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td></tr>\"\n",
    "\n",
    "table = train_function(table, traindf)\n",
    "\n",
    "\n",
    "table += \"</tbody></table>\\n\"\n",
    "print(table)\n",
    "#test on single era train on same era"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dcd1e9-f005-4297-b063-6a241d870d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_function(table, traindf, testdf):\n",
    "    num_samples = len(traindf)\n",
    "    train_eras = traindf['era'].unique()\n",
    "    test_eras = testdf['era'].unique()\n",
    "    trainf, testf= pd.DataFrame(), pd.DataFrame()\n",
    "    for train_era, test_era in zip(train_eras,test_eras):\n",
    "        trainf = traindf[traindf['era'] == train_era]\n",
    "        testf = testdf[testdf['era']==test_era]\n",
    "        \n",
    "        trainX, trainY = trainf[traindf.columns[2:-1]].values, trainf[traindf.columns[-1]].values\n",
    "        testX, testY = testf[testdf.columns[2:-1]].values, testf[testdf.columns[-1]].values\n",
    "        trainY = 4 * trainY\n",
    "        testY = 4 * testY\n",
    "        \n",
    "        numFeatures = 25\n",
    "        pca = PCA(n_components = numFeatures)\n",
    "        trainX = pca.fit_transform(trainX)\n",
    "        testX = pca.transform(testX)\n",
    "        print(\"pca\")\n",
    "        ds_train=MyDS(trainX,trainY,task='regression')\n",
    "        ds_test=MyDS(testX,testY,task='regression')\n",
    "        table += f\"<tr><td>{train_era}</td><td>{test_era}</td>\"\n",
    "        rxf, train_acc, test_acc = train_xgbr(ds_train, ds_test, verbose = False)\n",
    "        table += f\"<td>{train_acc:.2f}</td><td>{test_acc:.2f}</td>\"\n",
    "    \n",
    "        rlf, train_acc, test_acc = train_gbr(ds_train, ds_test, verbose = False)\n",
    "        table += f\"<td>{train_acc:.2f}</td><td>{test_acc:.2f}</td>\"\n",
    "    \n",
    "        rfr, train_acc, test_acc = train_rfr(ds_train, ds_test, verbose = False)\n",
    "        table += f\"<td>{train_acc:.2f}</td><td>{test_acc:.2f}</td>\"\n",
    "        print(\"reg\")\n",
    "        ds_train=MyDS(trainX,trainY,task='classification')\n",
    "        ds_test=MyDS(testX,testY,task='classification')\n",
    "    \n",
    "        cxf, train_acc, test_acc = train_xgbc(ds_train, ds_test, verbose = False)\n",
    "        table += f\"<td>{train_acc:.2f}</td><td>{test_acc:.2f}</td>\"\n",
    "    \n",
    "        clf, train_acc, test_acc = train_gbc(ds_train, ds_test, verbose = False)\n",
    "        table += f\"<td>{train_acc:.2f}</td><td>{test_acc:.2f}</td>\"\n",
    "    \n",
    "        rfc, train_acc, test_acc = train_rfc(ds_train, ds_test, verbose = False)\n",
    "        table += f\"<td>{train_acc:.2f}</td><td>{test_acc:.2f}</td>\"\n",
    "    \n",
    "        net, train_acc, test_acc = train_mlp(ds_train, ds_test, verbose = False)\n",
    "        table += f\"<td>{train_acc:.2f}</td><td>{test_acc:.2f}</td>\"\n",
    "    \n",
    "        table += \"</tr>\\n\"\n",
    "\n",
    "    return table    \n",
    "from tqdm import tqdm\n",
    "print(\"table\")\n",
    "table = \"<table>\\n\"\n",
    "table += \"<thead><caption>Training on data from a single era and test on different era.</caption>\\n\"\n",
    "table += \"<tr><th colspan=\\\"1\\\">Train Dataset</th><th colspan=\\\"1\\\">Test Dataset</th>\"\n",
    "table += \"<th colspan=\\\"2\\\">XgbR</th><th colspan=\\\"2\\\">GBR</th><th colspan=\\\"2\\\">RFR</th><th colspan=\\\"2\\\">XgbC</th><th colspan=\\\"2\\\">GBC</th><th colspan=\\\"2\\\">RFC</th><th colspan=\\\"2\\\">MLP C</th></tr>\\n\"\n",
    "table += \"</thead>\\n<tbody>\\n\"\n",
    "table += \"<tr><td></td><td></td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td></tr>\"\n",
    "\n",
    "table = train_function(table, traindf, valdf)\n",
    "\n",
    "\n",
    "table += \"</tbody></table>\\n\"\n",
    "print(table)\n",
    "#test on single era train on diff era"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7b717d-69cf-478c-8393-623ea3e89460",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
