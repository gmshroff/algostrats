{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0094e1-9c28-4a45-b58d-76969e66f2a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext jupyter_ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2542675d-45f3-485d-b5d5-54a33382b5d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%env OPENAI_API_KEY=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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4db24d-2348-4b3f-95ad-e0c9179e0e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%ai chatgpt \n",
    "# Describe the data in Out[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77c1b47-c143-48d4-8518-339cbb1172a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('../../temp_data/dfD.pickle','rb') as f: dfD=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840fe940-d7b9-4967-ac49-4e842bcb5722",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(dfD['DCM.NS'].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a624959-dfcf-4af8-adf9-e86248f49b0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%ai chatgpt \n",
    "Given a dictionary of dataframes indexed by ticker, write a python\n",
    "script that returns a dictionary similarly indexed with the output of\n",
    "calling check_entry() on each dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c907656-4307-4e15-851f-70c6fa86b59e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def check_all_entries(dict_of_dfs):\n",
    "    \"\"\"\n",
    "    Accepts a dictionary of dataframes indexed by ticker and returns a dictionary similarly\n",
    "    indexed with the output of calling check_entry() on each dataframe.\n",
    "    \n",
    "    Parameters:\n",
    "    dict_of_dfs (dict): Dictionary of DataFrames indexed by ticker\n",
    "    \n",
    "    Returns:\n",
    "    dict_of_results (dict): Dictionary of results returned by check_entry() function indexed by ticker\n",
    "    \"\"\"\n",
    "    dict_of_results = {}\n",
    "    \n",
    "    for ticker, df in dict_of_dfs.items():\n",
    "        dict_of_results[ticker] = check_entry(df)\n",
    "        \n",
    "    return dict_of_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf0e34f-4fca-4906-ad59-24fc056ec2ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def check_entry(df):\n",
    "    return 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629270e0-859a-463f-a472-0e976168cc7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "check_all_entries(dfD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76964fd-c7f6-48b1-b79a-430de7e43a0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%ai chatgpt \n",
    "Write a python function that takes in a dataframe and checks if the\n",
    "last k values in the Close column are increasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b19044e-7bea-46b3-b128-6c5e9b9b84df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def check_increasing(df, k):\n",
    "    \"\"\"\n",
    "    Accepts a DataFrame and a value k and checks if the last k values in the Close\n",
    "    column are increasing\n",
    "    \n",
    "    Parameters:\n",
    "    df (DataFrame): The DataFrame to check\n",
    "    k (int): The number of values to check\n",
    "    \n",
    "    Returns:\n",
    "    bool: True if the last k values in Close column are increasing, else False\n",
    "    \"\"\"\n",
    "    last_k = df['Close'].tail(k)\n",
    "    return all(last_k[i] < last_k[i+1] for i in range(k-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54033fa8-82db-47d6-8bb0-bab61478d9af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfD['DCM.NS'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7a1a93-716f-4f89-aaaa-fb658c4cf153",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(86):\n",
    "    check=check_increasing(dfD['DCM.NS'].iloc[0:i+3],3)\n",
    "    print(i,check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1debf04c-0ca4-41ed-930b-ac441d1269f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def check_numeric(df, col):\n",
    "    return df[col].dtype in ['float64', 'int64']\n",
    "\n",
    "def difference_cols(df, a, b):\n",
    "    df[f'{a}-{b}'] = df[a] - df[b]\n",
    "    return df, f'{a}-{b}'\n",
    "\n",
    "def get_ma_base_string(s):\n",
    "    idx = s.find('_ma_')\n",
    "    if idx == -1:\n",
    "        return None\n",
    "    return s[:idx]\n",
    "\n",
    "def moving_avg(df, col, window_size=3, center=False):\n",
    "    col_name = f'{col}_ma_{window_size}'\n",
    "    df[col_name] = df[col].rolling(window_size, min_periods=1, center=center).mean()\n",
    "    return df, col_name\n",
    "\n",
    "def slope(df, col, window):\n",
    "    col_name = f'{col}_slope_{window}'\n",
    "    df[col_name] = df[col].diff(periods=window).fillna(df[col])/window\n",
    "    return df, col_name\n",
    "\n",
    "def max_change_helper(seq):\n",
    "    ans = []\n",
    "    tracker = {i:0 for i in range(seq[-1]+1)}\n",
    "    for i in seq:\n",
    "        tracker[i] += 1\n",
    "        ans.append(tracker[i])\n",
    "    return ans\n",
    "\n",
    "def max_change(df, col):\n",
    "    inc_tracker = df[col].diff().lt(0).cumsum().values\n",
    "    dec_tracker = df[col].diff().gt(0).cumsum().values\n",
    "    \n",
    "    inc_values = max_change_helper(inc_tracker)\n",
    "    dec_values = max_change_helper(dec_tracker)\n",
    "    \n",
    "    combined = [inc_values[i]-1 if inc_values[i] >= dec_values[i] \\\n",
    "                else -dec_values[i]+1 for i in range(len(inc_values))]\n",
    "    \n",
    "    col_name = f'{col}_changelen'\n",
    "    df[col_name] = combined\n",
    "    return df, col_name\n",
    "\n",
    "def discretize(df, col):\n",
    "    stats = df[col].describe()\n",
    "    low_thresh, high_thresh = stats['25%'], stats['75%']\n",
    "    df[f'{col}_val'] = df[col].apply(lambda x: 0 if x<=low_thresh else 2 if x>=high_thresh else 1)\n",
    "    df[f'{col}_polarity'] = df[col].apply(lambda x: 1 if x>0 else -1)\n",
    "    # df[f'{col}_discrete'] = df[f'{col}_val'] + df[f'{col}_polarity']\n",
    "    return df, [f'{col}_val', f'{col}_polarity'] #, f'{col}_discrete']\n",
    "\n",
    "def add_features(feed):\n",
    "    columns_to_use = ['Open', 'Close']\n",
    "        \n",
    "    subtract_col_names = [('Open', 'Close')]\n",
    "    subtract_cols = []\n",
    "\n",
    "    for cols in subtract_col_names:\n",
    "        feed, added_col = difference_cols(feed, cols[0], cols[1])\n",
    "        subtract_cols.append(added_col)\n",
    "        \n",
    "    window_sizes = [1,5,10,20,50]\n",
    "    pre_avg_cols = columns_to_use + subtract_cols\n",
    "    avg_cols = []\n",
    "\n",
    "    for window in window_sizes:\n",
    "        for col in pre_avg_cols:\n",
    "            feed, added_col = moving_avg(feed, col, window_size=window)\n",
    "            avg_cols.append(added_col)\n",
    "                \n",
    "    pre_slope_cols = columns_to_use + subtract_cols + avg_cols\n",
    "    window_sizes = [1,3,5,10,15]\n",
    "    slope_cols = []\n",
    "\n",
    "    for window in window_sizes:\n",
    "        for col in pre_slope_cols:\n",
    "            feed, added_col = slope(feed, col, window=window)\n",
    "            slope_cols.append(added_col)\n",
    "            \n",
    "    intra_ma_diff_cols = []\n",
    "\n",
    "    for i in range(len(avg_cols)-1):\n",
    "        for j in range(i+1, len(avg_cols)):\n",
    "            colA, colB = avg_cols[i], avg_cols[j]\n",
    "            baseA, baseB = get_ma_base_string(colA), get_ma_base_string(colB)\n",
    "            if baseA != baseB: continue\n",
    "            \n",
    "            feed, added_col = difference_cols(feed, colA, colB)\n",
    "            intra_ma_diff_cols.append(added_col)\n",
    "            \n",
    "    pre_change_cols = columns_to_use + subtract_cols + avg_cols + slope_cols + intra_ma_diff_cols\n",
    "    change_cols = []\n",
    "\n",
    "    for col in pre_change_cols:\n",
    "        feed, added_col = max_change(feed, col)\n",
    "        change_cols.append(added_col)\n",
    "        \n",
    "    pre_discrete_cols = pre_change_cols + change_cols\n",
    "    discrete_cols = []\n",
    "\n",
    "    for col in pre_discrete_cols:\n",
    "        feed, added_cols = discretize(feed, col)\n",
    "        for added_col in added_cols: discrete_cols.append(added_col)\n",
    "        \n",
    "    return feed, pre_discrete_cols, discrete_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8725e8d0-a2b5-4398-af66-435cd5fff760",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def check_numeric(df, col):\n",
    "    return df[col].dtype in ['float64', 'int64']\n",
    "\n",
    "def difference_cols(df, a, b):\n",
    "    df[f'{a}-{b}'] = df[a] - df[b]\n",
    "    return df, f'{a}-{b}'\n",
    "\n",
    "def get_ma_base_string(s):\n",
    "    idx = s.find('_ma_')\n",
    "    if idx == -1:\n",
    "        return None\n",
    "    return s[:idx]\n",
    "\n",
    "def moving_avg(df, col, window_size=3, center=False):\n",
    "    col_name = f'{col}_ma_{window_size}'\n",
    "    df[col_name] = df[col].rolling(window_size, min_periods=1, center=center).mean()\n",
    "    return df, col_name\n",
    "\n",
    "def slope(df, col, window):\n",
    "    col_name = f'{col}_slope_{window}'\n",
    "    df[col_name] = df[col].diff(periods=window).fillna(df[col])/window\n",
    "    return df, col_name\n",
    "\n",
    "def max_change_helper(seq):\n",
    "    ans = []\n",
    "    tracker = {i:0 for i in range(seq[-1]+1)}\n",
    "    for i in seq:\n",
    "        tracker[i] += 1\n",
    "        ans.append(tracker[i])\n",
    "    return ans\n",
    "\n",
    "def max_change(df, col):\n",
    "    inc_tracker = df[col].diff().lt(0).cumsum().values\n",
    "    dec_tracker = df[col].diff().gt(0).cumsum().values\n",
    "    \n",
    "    inc_values = max_change_helper(inc_tracker)\n",
    "    dec_values = max_change_helper(dec_tracker)\n",
    "    \n",
    "    combined = [inc_values[i]-1 if inc_values[i] >= dec_values[i] \\\n",
    "                else -dec_values[i]+1 for i in range(len(inc_values))]\n",
    "    \n",
    "    col_name = f'{col}_changelen'\n",
    "    df[col_name] = combined\n",
    "    return df, col_name\n",
    "\n",
    "def discretize(df, col):\n",
    "    stats = df[col].describe()\n",
    "    low_thresh, high_thresh = stats['25%'], stats['75%']\n",
    "    df[f'{col}_val'] = df[col].apply(lambda x: 0 if x<=low_thresh else 2 if x>=high_thresh else 1)\n",
    "    df[f'{col}_polarity'] = df[col].apply(lambda x: 1 if x>0 else -1)\n",
    "    # df[f'{col}_discrete'] = df[f'{col}_val'] + df[f'{col}_polarity']\n",
    "    return df, [f'{col}_val', f'{col}_polarity'] #, f'{col}_discrete']\n",
    "\n",
    "def add_features(feed):\n",
    "    columns_to_use = ['Open', 'Close']\n",
    "        \n",
    "    subtract_col_names = [('Open', 'Close')]\n",
    "    subtract_cols = []\n",
    "\n",
    "    for cols in subtract_col_names:\n",
    "        feed, added_col = difference_cols(feed, cols[0], cols[1])\n",
    "        subtract_cols.append(added_col)\n",
    "        \n",
    "    window_sizes = [1,5,10,20,50]\n",
    "    pre_avg_cols = columns_to_use + subtract_cols\n",
    "    avg_cols = []\n",
    "\n",
    "    # for window in window_sizes:\n",
    "    #     for col in pre_avg_cols:\n",
    "    #         feed, added_col = moving_avg(feed, col, window_size=window)\n",
    "    #         avg_cols.append(added_col)\n",
    "                \n",
    "    pre_slope_cols = columns_to_use + subtract_cols\n",
    "    window_sizes = [1,3,5,10,15]\n",
    "    slope_cols = []\n",
    "\n",
    "    for window in window_sizes:\n",
    "        for col in pre_slope_cols:\n",
    "            feed, added_col = slope(feed, col, window=window)\n",
    "            slope_cols.append(added_col)\n",
    "            \n",
    "    intra_ma_diff_cols = []\n",
    "\n",
    "#     for i in range(len(avg_cols)-1):\n",
    "#         for j in range(i+1, len(avg_cols)):\n",
    "#             colA, colB = avg_cols[i], avg_cols[j]\n",
    "#             baseA, baseB = get_ma_base_string(colA), get_ma_base_string(colB)\n",
    "#             if baseA != baseB: continue\n",
    "            \n",
    "#             feed, added_col = difference_cols(feed, colA, colB)\n",
    "#             intra_ma_diff_cols.append(added_col)\n",
    "            \n",
    "    pre_change_cols = columns_to_use + subtract_cols + slope_cols\n",
    "    change_cols = []\n",
    "\n",
    "    for col in pre_change_cols:\n",
    "        feed, added_col = max_change(feed, col)\n",
    "        change_cols.append(added_col)\n",
    "        \n",
    "    pre_discrete_cols = pre_change_cols + change_cols\n",
    "    discrete_cols = []\n",
    "\n",
    "    for col in pre_discrete_cols:\n",
    "        feed, added_cols = discretize(feed, col)\n",
    "        for added_col in added_cols: discrete_cols.append(added_col)\n",
    "        \n",
    "    return feed, pre_discrete_cols, discrete_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a41ae8-d2c8-47a9-ad81-da511c0e636e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df=dfD['DCM.NS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc808091-d676-44fa-a2a1-1ed475947300",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3716e2b6-bd2f-4a72-acff-fdae32cc99d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_new=add_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4dbf031-31fb-4cd7-82a6-8d6a328121e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for c in df.columns: print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c024b207-55f3-46c4-aab7-e9b0ed923a48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_new[0][df_new[1][2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57dacba8-a1dd-4fbf-9d37-bee5a62f420a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%ai chatgpt \n",
    "The code in In[26] adds features to a dataframe. Write another version\n",
    "of the add_features function that adds these features incrementally, i.e.,\n",
    "given that features for the first k rows are already computed, this should\n",
    "efficiently compute the same features for the k+1st row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e709c1-80b2-41de-9696-96a441b58d0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
