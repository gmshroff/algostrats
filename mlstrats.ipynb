{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7889ded-dd8c-4c73-aadd-687cf98ddbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from datetime import datetime\n",
    "from datetime import datetime as dt\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "696c7465-65a9-4adc-93a1-4a3a39bf7cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from feeds.ipynb\n",
      "importing Jupyter notebook from featfuncs.ipynb\n",
      "importing Jupyter notebook from india_calendar.ipynb\n",
      "importing Jupyter notebook from utils.ipynb\n",
      "importing Jupyter notebook from models.ipynb\n"
     ]
    }
   ],
   "source": [
    "from feeds import BackFeed,DataFeed\n",
    "# import utils\n",
    "from models import MLP,SimpleLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f232463e-1584-4b8a-a719-9cfe9c141b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import anvil.server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f5a80ab-87c0-4eab-85f3-abb217ddcb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOADDATA=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84ea1524-7f70-4ffd-a053-83d8c5b64b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "OHLC_COLS=['Open_n','High_n','Low_n','Close_n']\n",
    "OHLC_ORIG=['Open','High','Low','Close']\n",
    "TA_COLS=['SMA_10', 'SMA_20','VOL_SMA_20','RSI_14','BBL_5_2.0','BBM_5_2.0','BBU_5_2.0',\n",
    "       'BBB_5_2.0', 'BBP_5_2.0','MACD_12_26_9','MACDh_12_26_9','MACDs_12_26_9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fedd9a94-3852-46e1-bdab-ae481a00a6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCustomUnpickler(pickle.Unpickler):\n",
    "    def find_class(self, module, name):\n",
    "        if module == \"__main__\":\n",
    "            module = \"mlstrats\"\n",
    "        return super().find_class(module, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd4b80a-bb56-44f2-928f-475a57571c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigFields():\n",
    "    def __init__(self):\n",
    "        self.flat_features=[]\n",
    "        self.prev_cols=[]\n",
    "        self.data_cols=['Open_n','High_n','Low_n','Close_n']+TA_COLS\n",
    "        self.tar_cols=['top1','top2','top3','bot1','bot2','bot3','(0.02, 0.01)','(0.01, 0.005)','(0.01, 0.02)','(0.005, 0.01)']\n",
    "#        \n",
    "#         self.data_cols_to_map=['Open_n','High_n','Low_n','Close_n']\n",
    "#         self.data_cols_mapped=['Open','High','Low','Close']\n",
    "#         self.ta_cols=TA_COLS\n",
    "#         self.data_cols_rest=self.ta_cols\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ea9593-f0f9-4850-a200-11bda515bcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelConfig():\n",
    "    def __init__(self,config,tickers):\n",
    "        self.config=config\n",
    "        self.tickers=tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959b5f92-bcf9-447a-ad4a-7f30ac8a58d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLConfig(ModelConfig):\n",
    "    def __init__(self,config,mlpshape,lstmshape,MLP6,MLP8,LSTM6,LSTM8,\n",
    "                 ds_scaler,cs_scaler,xs_scaler,tickers):\n",
    "        super().__init__(config,tickers)\n",
    "        self.mlpshape=mlpshape\n",
    "        self.lstmshape=lstmshape\n",
    "        self.MLP6dict=MLP6.state_dict()\n",
    "        self.MLP8dict=MLP8.state_dict()\n",
    "        self.LSTM6dict=LSTM6.state_dict()\n",
    "        self.LSTM8dict=LSTM8.state_dict()\n",
    "        self.ds_scaler=ds_scaler\n",
    "        self.cs_scaler=cs_scaler\n",
    "        self.xs_scaler=xs_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab497b92-51d2-405a-b27a-19a5e7043a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLBaseStrat():\n",
    "    def __init__(self):\n",
    "        self.logL=[]\n",
    "        self.train=False\n",
    "        self.model_type='ml'\n",
    "    def check_entry(self,df):\n",
    "        model_results=self.apply_model(df)\n",
    "        if LOADDATA:\n",
    "            o1=df.iloc[-1]['(0.02, 0.01)']\n",
    "            o3=df.iloc[-1]['(0.01, 0.02)']\n",
    "            print(model_results,o1,o3)\n",
    "        return self.make_decision(model_results)\n",
    "    def check_entry_batch(self,dfD):\n",
    "        decisionsD={}\n",
    "        log_entry={}\n",
    "        stopD={t:0 for t in dfD}\n",
    "        targetD={t:0 for t in dfD}\n",
    "        for t in dfD.keys():\n",
    "            model_results=self.apply_model(dfD[t])\n",
    "            decisionsD[t]=self.make_decision(model_results)\n",
    "            log_entry[t]=(model_results,dfD[t])\n",
    "        self.logL+=[log_entry]\n",
    "        return decisionsD,stopD,targetD\n",
    "    def check_exit_batch(self,dfD,posf):\n",
    "        def exit_fn(row):\n",
    "            return self.exit_predicate(row,dfD[row.ticker])\n",
    "        posf['to_exit']=posf.apply(exit_fn,axis=1).values\n",
    "        return posf\n",
    "    def exit_predicate(self,row,df):\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bdacdc-cb51-4955-8d8c-099a92d775af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLStrat(MLBaseStrat):\n",
    "    def __init__(self,modelConfig=None):\n",
    "        super().__init__()\n",
    "        self.init_models(modelConfig=modelConfig)\n",
    "        self.name='ml-strategy'\n",
    "    # Model Specific Functions\n",
    "    def init_models(self,modelConfig=None):\n",
    "        if modelConfig==None:\n",
    "            with open('./saved_models/modelConfig.pickle','rb') as f: \n",
    "                # self.modelConfig=pickle.load(f)\n",
    "                unpickler = MyCustomUnpickler(f)\n",
    "                self.modelConfig=unpickler.load()\n",
    "        else: self.modelConfig=modelConfig\n",
    "        self.config=self.modelConfig.config\n",
    "        self.data_cols=self.config.data_cols\n",
    "        input_size=len(self.data_cols)\n",
    "        self.mlpshape=self.modelConfig.mlpshape\n",
    "        self.MLP6=MLP(dims=self.mlpshape,lr=1e-3,task='classification')\n",
    "        self.MLP6.load_state_dict(self.modelConfig.MLP6dict)\n",
    "        self.MLP8=MLP(dims=self.mlpshape,lr=1e-3,task='classification')\n",
    "        self.MLP8.load_state_dict(self.modelConfig.MLP8dict)\n",
    "        self.lstmshape=self.modelConfig.lstmshape\n",
    "        self.LSTM6=SimpleLSTM(input_size=input_size,hidden_sizeL=self.lstmshape,output_size=4,lr=1e-3)\n",
    "        self.LSTM6.load_state_dict(self.modelConfig.LSTM6dict)\n",
    "        self.LSTM8=SimpleLSTM(input_size=input_size,hidden_sizeL=self.lstmshape,output_size=4,lr=1e-3)\n",
    "        self.LSTM8.load_state_dict(self.modelConfig.LSTM8dict)\n",
    "        self.ds_scaler=self.modelConfig.ds_scaler\n",
    "        self.cs_scaler=self.modelConfig.cs_scaler\n",
    "        self.xs_scaler=self.modelConfig.xs_scaler\n",
    "        self.style='flat'\n",
    "        self.tickers=self.modelConfig.tickers\n",
    "        if self.train==False:\n",
    "            self.MLP6.eval()\n",
    "            self.MLP8.eval()\n",
    "            self.LSTM6.eval()\n",
    "            self.LSTM8.eval()\n",
    "    def set_style(self,style='flat'):\n",
    "        self.style=style\n",
    "    def apply_MLP(self,df):\n",
    "        s=torch.tensor(df.iloc[-1][self.config.data_cols].values.astype(np.float)).float().unsqueeze(0)\n",
    "        x=torch.tensor(self.xs_scaler.transform(s)).float()\n",
    "        r6=self.MLP6(x)\n",
    "        r8=self.MLP8(x)\n",
    "        s1=torch.max(r6,1)[1]\n",
    "        s3=torch.max(r8,1)[1]\n",
    "        #self.logL+=['MLP',s,s1,s3]\n",
    "        return s1,s3,r6,r8\n",
    "    def apply_LSTM(self,df):\n",
    "        def cs(s):\n",
    "            return (s.shape[0]*s.shape[1],s.shape[2])\n",
    "        s=torch.tensor(df[self.config.data_cols].values.astype(np.float)).float().unsqueeze(0)\n",
    "        x=torch.tensor(self.ds_scaler.transform(s.reshape(cs(s))).reshape(s.shape)).float()\n",
    "        x=x[:,-40:,:]\n",
    "        r6=self.LSTM6(x)\n",
    "        r8=self.LSTM8(x)\n",
    "        s1=torch.max(r6,1)[1]\n",
    "        s3=torch.max(r8,1)[1]\n",
    "        #self.logL+=['LSTM',s,s1,s3]\n",
    "        return s1,s3,r6,r8,x\n",
    "    def apply_model(self,df):\n",
    "        if self.style=='flat':\n",
    "            s1,s3,r6,r8=self.apply_MLP(df)\n",
    "        elif self.style=='seq':\n",
    "            s1,s3,r6,r8,_=self.apply_LSTM(df)\n",
    "        return s1,s3,r6,r8\n",
    "    def make_decision(self,model_results):\n",
    "        s1,s3,_,_=model_results\n",
    "        if s1==3 or s1==2: return 1\n",
    "        elif s3==0 or s3==1: return -1\n",
    "        else: return 0\n",
    "    def Check(mlstrat,df):\n",
    "        return mlstrat.check_entry_batch(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
